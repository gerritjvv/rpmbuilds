<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Sqoop User Guide (v1.4.2)</title><link rel="stylesheet" href="docbook.css" type="text/css"><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"></head><body><div style="clear:both; margin-bottom: 4px"></div><div align="center"><a href="index.html"><img src="images/home.png" alt="Documentation Home"></a></div><span class="breadcrumbs"><div class="breadcrumbs"><span class="breadcrumb-node">Sqoop User Guide (v1.4.2)</span></div></span><div lang="en" class="article" title="Sqoop User Guide (v1.4.2)"><div class="titlepage"><div><div><h2 class="title"><a name="id335918"></a>Sqoop User Guide (v1.4.2)</h2></div></div><hr></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#_introduction">1. Introduction</a></span></dt><dt><span class="section"><a href="#_supported_releases">2. Supported Releases</a></span></dt><dt><span class="section"><a href="#_sqoop_releases">3. Sqoop Releases</a></span></dt><dt><span class="section"><a href="#_prerequisites">4. Prerequisites</a></span></dt><dt><span class="section"><a href="#_basic_usage">5. Basic Usage</a></span></dt><dt><span class="section"><a href="#_sqoop_tools">6. Sqoop Tools</a></span></dt><dd><dl><dt><span class="section"><a href="#_using_command_aliases">6.1. Using Command Aliases</a></span></dt><dt><span class="section"><a href="#_controlling_the_hadoop_installation">6.2. Controlling the Hadoop Installation</a></span></dt><dt><span class="section"><a href="#_using_generic_and_specific_arguments">6.3. Using Generic and Specific Arguments</a></span></dt><dt><span class="section"><a href="#_using_options_files_to_pass_arguments">6.4. Using Options Files to Pass Arguments</a></span></dt><dt><span class="section"><a href="#_using_tools">6.5. Using Tools</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_import_literal">7. <code class="literal">sqoop-import</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose">7.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax">7.2. Syntax</a></span></dt><dd><dl><dt><span class="section"><a href="#_connecting_to_a_database_server">7.2.1. Connecting to a Database Server</a></span></dt><dt><span class="section"><a href="#_selecting_the_data_to_import">7.2.2. Selecting the Data to Import</a></span></dt><dt><span class="section"><a href="#_free_form_query_imports">7.2.3. Free-form Query Imports</a></span></dt><dt><span class="section"><a href="#_controlling_parallelism">7.2.4. Controlling Parallelism</a></span></dt><dt><span class="section"><a href="#_controlling_the_import_process">7.2.5. Controlling the Import Process</a></span></dt><dt><span class="section"><a href="#_controlling_type_mapping">7.2.6. Controlling type mapping</a></span></dt><dt><span class="section"><a href="#_incremental_imports">7.2.7. Incremental Imports</a></span></dt><dt><span class="section"><a href="#_file_formats">7.2.8. File Formats</a></span></dt><dt><span class="section"><a href="#_large_objects">7.2.9. Large Objects</a></span></dt><dt><span class="section"><a href="#_importing_data_into_hive">7.2.10. Importing Data Into Hive</a></span></dt><dt><span class="section"><a href="#_importing_data_into_hbase">7.2.11. Importing Data Into HBase</a></span></dt></dl></dd><dt><span class="section"><a href="#_example_invocations">7.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_import_all_tables_literal">8. <code class="literal">sqoop-import-all-tables</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_2">8.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_2">8.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_2">8.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_export_literal">9. <code class="literal">sqoop-export</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_3">9.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_3">9.2. Syntax</a></span></dt><dt><span class="section"><a href="#_inserts_vs_updates">9.3. Inserts vs. Updates</a></span></dt><dt><span class="section"><a href="#_exports_and_transactions">9.4. Exports and Transactions</a></span></dt><dt><span class="section"><a href="#_failed_exports">9.5. Failed Exports</a></span></dt><dt><span class="section"><a href="#_example_invocations_3">9.6. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_saved_jobs">10. Saved Jobs</a></span></dt><dt><span class="section"><a href="#_literal_sqoop_job_literal">11. <code class="literal">sqoop-job</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_4">11.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_4">11.2. Syntax</a></span></dt><dt><span class="section"><a href="#_saved_jobs_and_passwords">11.3. Saved jobs and passwords</a></span></dt><dt><span class="section"><a href="#_saved_jobs_and_incremental_imports">11.4. Saved jobs and incremental imports</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_metastore_literal">12. <code class="literal">sqoop-metastore</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_5">12.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_5">12.2. Syntax</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_merge_literal">13. <code class="literal">sqoop-merge</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_6">13.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_6">13.2. Syntax</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_codegen_literal">14. <code class="literal">sqoop-codegen</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_7">14.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_7">14.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_4">14.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_create_hive_table_literal">15. <code class="literal">sqoop-create-hive-table</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_8">15.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_8">15.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_5">15.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_eval_literal">16. <code class="literal">sqoop-eval</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_9">16.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_9">16.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_6">16.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_list_databases_literal">17. <code class="literal">sqoop-list-databases</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_10">17.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_10">17.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_7">17.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_list_tables_literal">18. <code class="literal">sqoop-list-tables</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_11">18.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_11">18.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_8">18.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_help_literal">19. <code class="literal">sqoop-help</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_12">19.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_12">19.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_9">19.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_literal_sqoop_version_literal">20. <code class="literal">sqoop-version</code></a></span></dt><dd><dl><dt><span class="section"><a href="#_purpose_13">20.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_13">20.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_10">20.3. Example Invocations</a></span></dt></dl></dd><dt><span class="section"><a href="#_compatibility_notes">21. Compatibility Notes</a></span></dt><dd><dl><dt><span class="section"><a href="#_supported_databases">21.1. Supported Databases</a></span></dt><dt><span class="section"><a href="#_mysql">21.2. MySQL</a></span></dt><dd><dl><dt><span class="section"><a href="#_zerodatetimebehavior">21.2.1. zeroDateTimeBehavior</a></span></dt><dt><span class="section"><a href="#_literal_unsigned_literal_columns">21.2.2. <code class="literal">UNSIGNED</code> columns</a></span></dt><dt><span class="section"><a href="#_literal_blob_literal_and_literal_clob_literal_columns">21.2.3. <code class="literal">BLOB</code> and <code class="literal">CLOB</code> columns</a></span></dt><dt><span class="section"><a href="#_importing_views_in_direct_mode">21.2.4. Importing views in direct mode</a></span></dt><dt><span class="section"><a href="#_direct_mode_transactions">21.2.5. Direct-mode Transactions</a></span></dt></dl></dd><dt><span class="section"><a href="#_postgresql">21.3. PostgreSQL</a></span></dt><dd><dl><dt><span class="section"><a href="#_importing_views_in_direct_mode_2">21.3.1. Importing views in direct mode</a></span></dt></dl></dd><dt><span class="section"><a href="#_oracle">21.4. Oracle</a></span></dt><dd><dl><dt><span class="section"><a href="#_dates_and_times">21.4.1. Dates and Times</a></span></dt></dl></dd><dt><span class="section"><a href="#_schema_definition_in_hive">21.5. Schema Definition in Hive</a></span></dt></dl></dd><dt><span class="section"><a href="#_getting_support">22. Getting Support</a></span></dt><dt><span class="section"><a href="#_troubleshooting">23. Troubleshooting</a></span></dt><dd><dl><dt><span class="section"><a href="#_general_troubleshooting_process">23.1. General Troubleshooting Process</a></span></dt><dt><span class="section"><a href="#_specific_troubleshooting_tips">23.2. Specific Troubleshooting Tips</a></span></dt><dd><dl><dt><span class="section"><a href="#_oracle_connection_reset_errors">23.2.1. Oracle: Connection Reset Errors</a></span></dt><dt><span class="section"><a href="#_oracle_case_sensitive_catalog_query_errors">23.2.2. Oracle: Case-Sensitive Catalog Query Errors</a></span></dt><dt><span class="section"><a href="#_mysql_connection_failure">23.2.3. MySQL: Connection Failure</a></span></dt><dt><span class="section"><a href="#_oracle_ora_00933_error_sql_command_not_properly_ended">23.2.4. Oracle: ORA-00933 error (SQL command not properly ended)</a></span></dt><dt><span class="section"><a href="#_mysql_import_of_tinyint_1_from_mysql_behaves_strangely">23.2.5. MySQL: Import of TINYINT(1) from MySQL behaves strangely</a></span></dt></dl></dd></dl></dd></dl></div><pre class="screen">  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  "License"); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.</pre><div class="section" title="1. Introduction"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_introduction"></a>1. Introduction</h2></div></div></div><p>Sqoop is a tool designed to transfer data between Hadoop and
relational databases. You can use Sqoop to import data from a
relational database management system (RDBMS) such as MySQL or Oracle
into the Hadoop Distributed File System (HDFS),
transform the data in Hadoop MapReduce, and then export the data back
into an RDBMS.</p><p>Sqoop automates most of this process, relying on the database to
describe the schema for the data to be imported. Sqoop uses MapReduce
to import and export the data, which provides parallel operation as
well as fault tolerance.</p><p>This document describes how to get started using Sqoop to move data
between databases and Hadoop and provides reference information for
the operation of the Sqoop command-line tool suite. This document is
intended for:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
System and application programmers
</li><li class="listitem">
System administrators
</li><li class="listitem">
Database administrators
</li><li class="listitem">
Data analysts
</li><li class="listitem">
Data engineers
</li></ul></div></div><div class="section" title="2. Supported Releases"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_supported_releases"></a>2. Supported Releases</h2></div></div></div><p>This documentation applies to Sqoop v1.4.2.</p></div><div class="section" title="3. Sqoop Releases"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_sqoop_releases"></a>3. Sqoop Releases</h2></div></div></div><p>Sqoop is an open source software product of the Apache Software Foundation.</p><p>Software development for Sqoop occurs at <a class="ulink" href="http://svn.apache.org/repos/asf/sqoop/trunk" target="_top">http://svn.apache.org/repos/asf/sqoop/trunk</a>.
At that site you can obtain:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
New releases of Sqoop as well as its most recent source code
</li><li class="listitem">
An issue tracker
</li><li class="listitem">
A wiki that contains Sqoop documentation
</li></ul></div><p>Sqoop is compatible with Apache Hadoop 0.21 and Cloudera&#8217;s
Distribution of Hadoop version 3.</p></div><div class="section" title="4. Prerequisites"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_prerequisites"></a>4. Prerequisites</h2></div></div></div><p>The following prerequisite knowledge is required for this product:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Basic computer technology and terminology
</li><li class="listitem">
Familiarity with command-line interfaces such as <code class="literal">bash</code>
</li><li class="listitem">
Relational database management systems
</li><li class="listitem">
Basic familiarity with the purpose and operation of Hadoop
</li></ul></div><p>Before you can use Sqoop, a release of Hadoop must be installed and
configured. We recommend that you download Cloudera&#8217;s Distribution
for Hadoop (CDH3) from the Cloudera Software Archive at
<a class="ulink" href="http://archive.cloudera.com" target="_top">http://archive.cloudera.com</a> for straightforward installation of Hadoop
on Linux systems.</p><p>This document assumes you are using a Linux or Linux-like environment.
If you are using Windows, you may be able to use cygwin to accomplish
most of the following tasks. If you are using Mac OS X, you should see
few (if any) compatibility errors. Sqoop is predominantly operated and
tested on Linux.</p></div><div class="section" title="5. Basic Usage"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_basic_usage"></a>5. Basic Usage</h2></div></div></div><p>With Sqoop, you can <span class="emphasis"><em>import</em></span> data from a relational database system into
HDFS. The input to the import process is a database table. Sqoop
will read the table row-by-row into HDFS. The output of this import
process is a set of files containing a copy of the imported table.
The import process is performed in parallel. For this reason, the
output will be in multiple files. These files may be delimited text
files (for example, with commas or tabs separating each field), or
binary Avro or SequenceFiles containing serialized record data.</p><p>A by-product of the import process is a generated Java class which
can encapsulate one row of the imported table. This class is used
during the import process by Sqoop itself. The Java source code for
this class is also provided to you, for use in subsequent MapReduce
processing of the data. This class can serialize and deserialize data
to and from the SequenceFile format. It can also parse the
delimited-text form of a record. These abilities allow you to quickly
develop MapReduce applications that use the HDFS-stored records in
your processing pipeline. You are also free to parse the delimiteds
record data yourself, using any other tools you prefer.</p><p>After manipulating the imported records (for example, with MapReduce
or Hive) you may have a result data set which you can then <span class="emphasis"><em>export</em></span>
back to the relational database. Sqoop&#8217;s export process will read
a set of delimited text files from HDFS in parallel, parse them into
records, and insert them as new rows in a target database table, for
consumption by external applications or users.</p><p>Sqoop includes some other commands which allow you to inspect the
database you are working with. For example, you can list the available
database schemas (with the <code class="literal">sqoop-list-databases</code> tool) and tables
within a schema (with the <code class="literal">sqoop-list-tables</code> tool). Sqoop also
includes a primitive SQL execution shell (the <code class="literal">sqoop-eval</code> tool).</p><p>Most aspects of the import, code generation, and export processes can
be customized. You can control the specific row range or columns imported.
You can specify particular delimiters and escape characters for the
file-based representation of the data, as well as the file format
used.  You can also control the class or package names used in
generated code. Subsequent sections of this document explain how to
specify these and other arguments to Sqoop.</p></div><div class="section" title="6. Sqoop Tools"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_sqoop_tools"></a>6. Sqoop Tools</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_using_command_aliases">6.1. Using Command Aliases</a></span></dt><dt><span class="section"><a href="#_controlling_the_hadoop_installation">6.2. Controlling the Hadoop Installation</a></span></dt><dt><span class="section"><a href="#_using_generic_and_specific_arguments">6.3. Using Generic and Specific Arguments</a></span></dt><dt><span class="section"><a href="#_using_options_files_to_pass_arguments">6.4. Using Options Files to Pass Arguments</a></span></dt><dt><span class="section"><a href="#_using_tools">6.5. Using Tools</a></span></dt></dl></div><p>Sqoop is a collection of related tools. To use Sqoop, you specify the
tool you want to use and the arguments that control the tool.</p><p>If Sqoop is compiled from its own source, you can run Sqoop without a formal
installation process by running the <code class="literal">bin/sqoop</code> program. Users
of a packaged deployment of Sqoop (such as an RPM shipped with Cloudera&#8217;s
Distribution for Hadoop) will see this program installed as <code class="literal">/usr/bin/sqoop</code>.
The remainder of this documentation will refer to this program as
<code class="literal">sqoop</code>. For example:</p><pre class="screen">$ sqoop tool-name [tool-arguments]</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The following examples that begin with a <code class="literal">$</code> character indicate
that the commands must be entered at a terminal prompt (such as
<code class="literal">bash</code>). The <code class="literal">$</code> character represents the prompt itself; you should
not start these commands by typing a <code class="literal">$</code>. You can also enter commands
inline in the text of a paragraph; for example, <code class="literal">sqoop help</code>. These
examples do not show a <code class="literal">$</code> prefix, but you should enter them the same
way.  Don&#8217;t confuse the <code class="literal">$</code> shell prompt in the examples with the <code class="literal">$</code>
that precedes an environment variable name. For example, the string
literal <code class="literal">$HADOOP_HOME</code> includes a "<code class="literal">$</code>".</p></td></tr></table></div><p>Sqoop ships with a help tool. To display a list of all available
tools, type the following command:</p><pre class="screen">$ sqoop help
usage: sqoop COMMAND [ARGS]

Available commands:
  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  eval               Evaluate a SQL statement and display the results
  export             Export an HDFS directory to a database table
  help               List available commands
  import             Import a table from a database to HDFS
  import-all-tables  Import tables from a database to HDFS
  list-databases     List available databases on a server
  list-tables        List available tables in a database
  version            Display version information

See 'sqoop help COMMAND' for information on a specific command.</pre><p>You can display help for a specific tool by entering: <code class="literal">sqoop help
(tool-name)</code>; for example, <code class="literal">sqoop help import</code>.</p><p>You can also add the <code class="literal">--help</code> argument to any command: <code class="literal">sqoop import
--help</code>.</p><div class="section" title="6.1. Using Command Aliases"><div class="titlepage"><div><div><h3 class="title"><a name="_using_command_aliases"></a>6.1. Using Command Aliases</h3></div></div></div><p>In addition to typing the <code class="literal">sqoop (toolname)</code> syntax, you can use alias
scripts that specify the <code class="literal">sqoop-(toolname)</code> syntax. For example, the
scripts <code class="literal">sqoop-import</code>, <code class="literal">sqoop-export</code>, etc. each select a specific
tool.</p></div><div class="section" title="6.2. Controlling the Hadoop Installation"><div class="titlepage"><div><div><h3 class="title"><a name="_controlling_the_hadoop_installation"></a>6.2. Controlling the Hadoop Installation</h3></div></div></div><p>You invoke Sqoop through the program launch capability provided by
Hadoop. The <code class="literal">sqoop</code> command-line program is a wrapper which runs the
<code class="literal">bin/hadoop</code> script shipped with Hadoop. If you have multiple
installations of Hadoop present on your machine, you can select the
Hadoop installation by setting the <code class="literal">$HADOOP_HOME</code> environment
variable.</p><p>For example:</p><pre class="screen">$ HADOOP_HOME=/path/to/some/hadoop sqoop import --arguments...</pre><p>or:</p><pre class="screen">$ export HADOOP_HOME=/some/path/to/hadoop
$ sqoop import --arguments...</pre><p>If <code class="literal">$HADOOP_HOME</code> is not set, Sqoop will use the default installation
location for Cloudera&#8217;s Distribution for Hadoop, <code class="literal">/usr/lib/hadoop</code>.</p><p>The active Hadoop configuration is loaded from <code class="literal">$HADOOP_HOME/conf/</code>,
unless the <code class="literal">$HADOOP_CONF_DIR</code> environment variable is set.</p></div><div class="section" title="6.3. Using Generic and Specific Arguments"><div class="titlepage"><div><div><h3 class="title"><a name="_using_generic_and_specific_arguments"></a>6.3. Using Generic and Specific Arguments</h3></div></div></div><p>To control the operation of each Sqoop tool, you use generic and
specific arguments.</p><p>For example:</p><pre class="screen">$ sqoop help import
usage: sqoop import [GENERIC-ARGS] [TOOL-ARGS]

Common arguments:
   --connect &lt;jdbc-uri&gt;     Specify JDBC connect string
   --connect-manager &lt;jdbc-uri&gt;     Specify connection manager class to use
   --driver &lt;class-name&gt;    Manually specify JDBC driver class to use
   --hadoop-home &lt;dir&gt;      Override $HADOOP_HOME
   --help                   Print usage instructions
-P                          Read password from console
   --password &lt;password&gt;    Set authentication password
   --username &lt;username&gt;    Set authentication username
   --verbose                Print more information while working

[...]

Generic Hadoop command-line arguments:
(must preceed any tool-specific arguments)
Generic options supported are
-conf &lt;configuration file&gt;     specify an application configuration file
-D &lt;property=value&gt;            use value for given property
-fs &lt;local|namenode:port&gt;      specify a namenode
-jt &lt;local|jobtracker:port&gt;    specify a job tracker
-files &lt;comma separated list of files&gt;    specify comma separated files to be copied to the map reduce cluster
-libjars &lt;comma separated list of jars&gt;    specify comma separated jar files to include in the classpath.
-archives &lt;comma separated list of archives&gt;    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]</pre><p>You must supply the generic arguments <code class="literal">-conf</code>, <code class="literal">-D</code>, and so on after the
tool name but <span class="strong"><strong>before</strong></span> any tool-specific arguments (such as
<code class="literal">--connect</code>). Note that generic Hadoop arguments are preceeded by a
single dash character (<code class="literal">-</code>), whereas tool-specific arguments start
with two dashes (<code class="literal">--</code>), unless they are single character arguments such as <code class="literal">-P</code>.</p><p>The <code class="literal">-conf</code>, <code class="literal">-D</code>, <code class="literal">-fs</code> and <code class="literal">-jt</code> arguments control the configuration
and Hadoop server settings. For example, the <code class="literal">-D mapred.job.name=&lt;job_name&gt;</code> can
be used to set the name of the MR job that Sqoop launches, if not specified,
the name defaults to the jar name for the job - which is derived from the used
table name.</p><p>The <code class="literal">-files</code>, <code class="literal">-libjars</code>, and <code class="literal">-archives</code> arguments are not typically used with
Sqoop, but they are included as part of Hadoop&#8217;s internal argument-parsing
system.</p></div><div class="section" title="6.4. Using Options Files to Pass Arguments"><div class="titlepage"><div><div><h3 class="title"><a name="_using_options_files_to_pass_arguments"></a>6.4. Using Options Files to Pass Arguments</h3></div></div></div><p>When using Sqoop, the command line options that do not change from
invocation to invocation can be put in an options file for convenience.
An options file is a text file where each line identifies an option in
the order that it appears otherwise on the command line. Option files
allow specifying a single option on multiple lines by using the
back-slash character at the end of intermediate lines. Also supported
are comments within option files that begin with the hash character.
Comments must be specified on a new line and may not be mixed with
option text. All comments and empty lines are ignored when option
files are expanded. Unless options appear as quoted strings, any
leading or trailing spaces are ignored. Quoted strings if used must
not extend beyond the line on which they are specified.</p><p>Option files can be specified anywhere in the command line as long as
the options within them follow the otherwise prescribed rules of
options ordering. For instance, regardless of where the options are
loaded from, they must follow the ordering such that generic options
appear first, tool specific options next, finally followed by options
that are intended to be passed to child programs.</p><p>To specify an options file, simply create an options file in a
convenient location and pass it to the command line via
<code class="literal">--options-file</code> argument.</p><p>Whenever an options file is specified, it is expanded on the
command line before the tool is invoked. You can specify more than
one option files within the same invocation if needed.</p><p>For example, the following Sqoop invocation for import can
be specified alternatively as shown below:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://localhost/db --username foo --table TEST

$ sqoop --options-file /users/homer/work/import.txt --table TEST</pre><p>where the options file <code class="literal">/users/homer/work/import.txt</code> contains the following:</p><pre class="screen">import
--connect
jdbc:mysql://localhost/db
--username
foo</pre><p>The options file can have empty lines and comments for readability purposes.
So the above example would work exactly the same if the options file
<code class="literal">/users/homer/work/import.txt</code> contained the following:</p><pre class="screen">#
# Options file for Sqoop import
#

# Specifies the tool being invoked
import

# Connect parameter and value
--connect
jdbc:mysql://localhost/db

# Username parameter and value
--username
foo

#
# Remaining options should be specified in the command line.
#</pre></div><div class="section" title="6.5. Using Tools"><div class="titlepage"><div><div><h3 class="title"><a name="_using_tools"></a>6.5. Using Tools</h3></div></div></div><p>The following sections will describe each tool&#8217;s operation. The
tools are listed in the most likely order you will find them useful.</p></div></div><div class="section" title="7. sqoop-import"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_import_literal"></a>7. <code class="literal">sqoop-import</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose">7.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax">7.2. Syntax</a></span></dt><dd><dl><dt><span class="section"><a href="#_connecting_to_a_database_server">7.2.1. Connecting to a Database Server</a></span></dt><dt><span class="section"><a href="#_selecting_the_data_to_import">7.2.2. Selecting the Data to Import</a></span></dt><dt><span class="section"><a href="#_free_form_query_imports">7.2.3. Free-form Query Imports</a></span></dt><dt><span class="section"><a href="#_controlling_parallelism">7.2.4. Controlling Parallelism</a></span></dt><dt><span class="section"><a href="#_controlling_the_import_process">7.2.5. Controlling the Import Process</a></span></dt><dt><span class="section"><a href="#_controlling_type_mapping">7.2.6. Controlling type mapping</a></span></dt><dt><span class="section"><a href="#_incremental_imports">7.2.7. Incremental Imports</a></span></dt><dt><span class="section"><a href="#_file_formats">7.2.8. File Formats</a></span></dt><dt><span class="section"><a href="#_large_objects">7.2.9. Large Objects</a></span></dt><dt><span class="section"><a href="#_importing_data_into_hive">7.2.10. Importing Data Into Hive</a></span></dt><dt><span class="section"><a href="#_importing_data_into_hbase">7.2.11. Importing Data Into HBase</a></span></dt></dl></dd><dt><span class="section"><a href="#_example_invocations">7.3. Example Invocations</a></span></dt></dl></div><div class="section" title="7.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose"></a>7.1. Purpose</h3></div></div></div><p>The <code class="literal">import</code> tool imports an individual table from an RDBMS to HDFS.
Each row from a table is represented as a separate record in HDFS.
Records can be stored as text files (one record per line), or in
binary representation as Avro or SequenceFiles.</p></div><div class="section" title="7.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax"></a>7.2. Syntax</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_connecting_to_a_database_server">7.2.1. Connecting to a Database Server</a></span></dt><dt><span class="section"><a href="#_selecting_the_data_to_import">7.2.2. Selecting the Data to Import</a></span></dt><dt><span class="section"><a href="#_free_form_query_imports">7.2.3. Free-form Query Imports</a></span></dt><dt><span class="section"><a href="#_controlling_parallelism">7.2.4. Controlling Parallelism</a></span></dt><dt><span class="section"><a href="#_controlling_the_import_process">7.2.5. Controlling the Import Process</a></span></dt><dt><span class="section"><a href="#_controlling_type_mapping">7.2.6. Controlling type mapping</a></span></dt><dt><span class="section"><a href="#_incremental_imports">7.2.7. Incremental Imports</a></span></dt><dt><span class="section"><a href="#_file_formats">7.2.8. File Formats</a></span></dt><dt><span class="section"><a href="#_large_objects">7.2.9. Large Objects</a></span></dt><dt><span class="section"><a href="#_importing_data_into_hive">7.2.10. Importing Data Into Hive</a></span></dt><dt><span class="section"><a href="#_importing_data_into_hbase">7.2.11. Importing Data Into HBase</a></span></dt></dl></div><pre class="screen">$ sqoop import (generic-args) (import-args)
$ sqoop-import (generic-args) (import-args)</pre><p>While the Hadoop generic arguments must precede any import arguments,
you can type the import arguments in any order with respect to one
another.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>In this document, arguments are grouped into collections
organized by function. Some collections are present in several tools
(for example, the "common" arguments). An extended description of their
functionality is given only on the first presentation in this
document.</p></td></tr></table></div><div class="table"><a name="id382798"></a><p class="title"><b>Table 1. Common arguments</b></p><div class="table-contents"><table summary="Common arguments" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connect &lt;jdbc-uri&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify JDBC connect string
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connection-manager &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify connection manager class to                                          use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--driver &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Manually specify JDBC driver class                                          to use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hadoop-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override $HADOOP_HOME
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-P</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Read password from console
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--password &lt;password&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication password
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--username &lt;username&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication username
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print more information while working
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--connection-param-file &lt;filename&gt;</code>
    </td><td style="" align="left">
    Optional properties file that                                          provides connection parameters
    </td></tr></tbody></table></div></div><br class="table-break"><div class="section" title="7.2.1. Connecting to a Database Server"><div class="titlepage"><div><div><h4 class="title"><a name="_connecting_to_a_database_server"></a>7.2.1. Connecting to a Database Server</h4></div></div></div><p>Sqoop is designed to import tables from a database into HDFS. To do
so, you must specify a <span class="emphasis"><em>connect string</em></span> that describes how to connect to the
database. The <span class="emphasis"><em>connect string</em></span> is similar to a URL, and is communicated to
Sqoop with the <code class="literal">--connect</code> argument. This describes the server and
database to connect to; it may also specify the port. For example:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://database.example.com/employees</pre><p>This string will connect to a MySQL database named <code class="literal">employees</code> on the
host <code class="literal">database.example.com</code>. It&#8217;s important that you <span class="strong"><strong>do not</strong></span> use the URL
<code class="literal">localhost</code> if you intend to use Sqoop with a distributed Hadoop
cluster. The connect string you supply will be used on TaskTracker nodes
throughout your MapReduce cluster; if you specify the
literal name <code class="literal">localhost</code>, each node will connect to a different
database (or more likely, no database at all). Instead, you should use
the full hostname or IP address of the database host that can be seen
by all your remote nodes.</p><p>You might need to authenticate against the database before you can
access it. You can use the <code class="literal">--username</code> and <code class="literal">--password</code> or <code class="literal">-P</code> parameters
to supply a username and a password to the database. For example:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://database.example.com/employees \
    --username aaron --password 12345</pre><div class="warning" title="Warning" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Warning"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Warning]" src="images/warning.png"></td><th align="left">Warning</th></tr><tr><td align="left" valign="top"><p>The <code class="literal">--password</code> parameter is insecure, as other users may
be able to read your password from the command-line arguments via
the output of programs such as <code class="literal">ps</code>. The <span class="strong"><strong><code class="literal">-P</code></strong></span> argument will read
a password from a console prompt, and is the preferred method of
entering credentials. Credentials may still be transferred between
nodes of the MapReduce cluster using insecure means.</p></td></tr></table></div><p>Sqoop automatically supports several databases, including MySQL.  Connect
strings beginning with <code class="literal">jdbc:mysql://</code> are handled automatically in Sqoop.  (A
full list of databases with built-in support is provided in the "Supported
Databases" section. For some, you may need to install the JDBC driver
yourself.)</p><p>You can use Sqoop with any other
JDBC-compliant database. First, download the appropriate JDBC
driver for the type of database you want to import, and install the .jar
file in the <code class="literal">$SQOOP_HOME/lib</code> directory on your client machine. (This will
be <code class="literal">/usr/lib/sqoop/lib</code> if you installed from an RPM or Debian package.)
Each driver <code class="literal">.jar</code> file also has a specific driver class which defines
the entry-point to the driver. For example, MySQL&#8217;s Connector/J library has
a driver class of <code class="literal">com.mysql.jdbc.Driver</code>. Refer to your database
vendor-specific documentation to determine the main driver class.
This class must be provided as an argument to Sqoop with <code class="literal">--driver</code>.</p><p>For example, to connect to a SQLServer database, first download the driver from
microsoft.com and install it in your Sqoop lib path.</p><p>Then run Sqoop. For example:</p><pre class="screen">$ sqoop import --driver com.microsoft.jdbc.sqlserver.SQLServerDriver \
    --connect &lt;connect-string&gt; ...</pre><p>When connecting to a database using JDBC, you can optionally specify extra
JDBC parameters via a property file using the option
<code class="literal">--connection-param-file</code>. The contents of this file are parsed as standard
Java properties and passed into the driver while creating a connection.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The parameters specified via the optional property file are only
applicable to JDBC connections. Any fastpath connectors that use connections
other than JDBC will ignore these parameters.</p></td></tr></table></div><div class="table"><a name="id383212"></a><p class="title"><b>Table 2. Import control arguments:</b></p><div class="table-contents"><table summary="Import control arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--append</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Append data to an existing dataset                                  in HDFS
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--as-avrodatafile</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Imports data to Avro Data Files
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--as-sequencefile</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Imports data to SequenceFiles
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--as-textfile</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Imports data as plain text (default)
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--boundary-query &lt;statement&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Boundary query to use for creating splits
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--columns &lt;col,col,col&#8230;&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Columns to import from table
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--direct</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Use direct import fast path
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--direct-split-size &lt;n&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Split the input stream every <span class="emphasis"><em>n</em></span> bytes                                  when importing in direct mode
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--inline-lob-limit &lt;n&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set the maximum size for an inline LOB
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-m,--num-mappers &lt;n&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Use <span class="emphasis"><em>n</em></span> map tasks to import in parallel
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-e,--query &lt;statement&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Import the results of <span class="emphasis"><em><code class="literal">statement</code></em></span>.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--split-by &lt;column-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Column of the table used to split work                                  units
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--table &lt;table-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Table to read
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--target-dir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    HDFS destination dir
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--warehouse-dir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    HDFS parent for table destination
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--where &lt;where clause&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    WHERE clause to use during import
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-z,--compress</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Enable compression
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--compression-codec &lt;c&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Use Hadoop codec (default gzip)
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--null-string &lt;null-string&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    The string to be written for a null                                  value for string columns
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--null-non-string &lt;null-string&gt;</code>
    </td><td style="" align="left">
    The string to be written for a null                                  value for non-string columns
    </td></tr></tbody></table></div></div><br class="table-break"><p>The <code class="literal">--null-string</code> and <code class="literal">--null-non-string</code> arguments are optional.\
If not specified, then the string "null" will be used.</p></div><div class="section" title="7.2.2. Selecting the Data to Import"><div class="titlepage"><div><div><h4 class="title"><a name="_selecting_the_data_to_import"></a>7.2.2. Selecting the Data to Import</h4></div></div></div><p>Sqoop typically imports data in a table-centric fashion. Use the
<code class="literal">--table</code> argument to select the table to import. For example, <code class="literal">--table
employees</code>. This argument can also identify a <code class="literal">VIEW</code> or other table-like
entity in a database.</p><p>By default, all columns within a table are selected for import.
Imported data is written to HDFS in its "natural order;" that is, a
table containing columns A, B, and C result in an import of data such
as:</p><pre class="screen">A1,B1,C1
A2,B2,C2
...</pre><p>You can select a subset of columns and control their ordering by using
the <code class="literal">--columns</code> argument. This should include a comma-delimited list
of columns to import. For example: <code class="literal">--columns "name,employee_id,jobtitle"</code>.</p><p>You can control which rows are imported by adding a SQL <code class="literal">WHERE</code> clause
to the import statement. By default, Sqoop generates statements of the
form <code class="literal">SELECT &lt;column list&gt; FROM &lt;table name&gt;</code>. You can append a
<code class="literal">WHERE</code> clause to this with the <code class="literal">--where</code> argument. For example: <code class="literal">--where
"id &gt; 400"</code>. Only rows where the <code class="literal">id</code> column has a value greater than
400 will be imported.</p><p>By default sqoop will use query <code class="literal">select min(&lt;split-by&gt;), max(&lt;split-by&gt;) from
&lt;table name&gt;</code> to find out boundaries for creating splits. In some cases this query
is not the most optimal so you can specify any arbitrary query returning two
numeric columns using <code class="literal">--boundary-query</code> argument.</p></div><div class="section" title="7.2.3. Free-form Query Imports"><div class="titlepage"><div><div><h4 class="title"><a name="_free_form_query_imports"></a>7.2.3. Free-form Query Imports</h4></div></div></div><p>Sqoop can also import the result set of an arbitrary SQL query. Instead of
using the <code class="literal">--table</code>, <code class="literal">--columns</code> and <code class="literal">--where</code> arguments, you can specify
a SQL statement with the <code class="literal">--query</code> argument.</p><p>When importing a free-form query, you must specify a destination directory
with <code class="literal">--target-dir</code>.</p><p>If you want to import the results of a query in parallel, then each map task
will need to execute a copy of the query, with results partitioned by bounding
conditions inferred by Sqoop. Your query must include the token <code class="literal">$CONDITIONS</code>
which each Sqoop process will replace with a unique condition expression.
You must also select a splitting column with <code class="literal">--split-by</code>.</p><p>For example:</p><pre class="screen">$ sqoop import \
  --query 'SELECT a.*, b.* FROM a JOIN b on (a.id == b.id) WHERE $CONDITIONS' \
  --split-by a.id --target-dir /user/foo/joinresults</pre><p>Alternately, the query can be executed once and imported serially, by
specifying a single map task with <code class="literal">-m 1</code>:</p><pre class="screen">$ sqoop import \
  --query 'SELECT a.*, b.* FROM a JOIN b on (a.id == b.id) WHERE $CONDITIONS' \
  -m 1 --target-dir /user/foo/joinresults</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>If you are issuing the query wrapped with double quotes ("),
you will have to use <code class="literal">\$CONDITIONS</code> instead of just <code class="literal">$CONDITIONS</code>
to disallow your shell from treating it as a shell variable.
For example, a double quoted query may look like:
<code class="literal">"SELECT * FROM x WHERE a='foo' AND \$CONDITIONS"</code></p></td></tr></table></div><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>The facility of using free-form query in the current version of Sqoop
is limited to simple queries where there are no ambiguous projections and
no <code class="literal">OR</code> conditions in the <code class="literal">WHERE</code> clause. Use of complex queries such as
queries that have sub-queries or joins leading to ambiguous projections can
lead to unexpected results.</p></td></tr></table></div></div><div class="section" title="7.2.4. Controlling Parallelism"><div class="titlepage"><div><div><h4 class="title"><a name="_controlling_parallelism"></a>7.2.4. Controlling Parallelism</h4></div></div></div><p>Sqoop imports data in parallel from most database sources. You can
specify the number
of map tasks (parallel processes) to use to perform the import by
using the <code class="literal">-m</code> or <code class="literal">--num-mappers</code> argument. Each of these arguments
takes an integer value which corresponds to the degree of parallelism
to employ. By default, four tasks are used. Some databases may see
improved performance by increasing this value to 8 or 16. Do not
increase the degree of parallelism greater than that available within
your MapReduce cluster; tasks will run serially and will likely
increase the amount of time required to perform the import. Likewise,
do not increase the degree of parallism higher than that which your
database can reasonably support. Connecting 100 concurrent clients to
your database may increase the load on the database server to a point
where performance suffers as a result.</p><p>When performing parallel imports, Sqoop needs a criterion by which it
can split the workload. Sqoop uses a <span class="emphasis"><em>splitting column</em></span> to split the
workload. By default, Sqoop will identify the primary key column (if
present) in a table and use it as the splitting column. The low and
high values for the splitting column are retrieved from the database,
and the map tasks operate on evenly-sized components of the total
range. For example, if you had a table with a primary key column of
<code class="literal">id</code> whose minimum value was 0 and maximum value was 1000, and Sqoop
was directed to use 4 tasks, Sqoop would run four processes which each
execute SQL statements of the form <code class="literal">SELECT * FROM sometable WHERE id
&gt;= lo AND id &lt; hi</code>, with <code class="literal">(lo, hi)</code> set to (0, 250), (250, 500),
(500, 750), and (750, 1001) in the different tasks.</p><p>If the actual values for the primary key are not uniformly distributed
across its range, then this can result in unbalanced tasks. You should
explicitly choose a different column with the <code class="literal">--split-by</code> argument.
For example, <code class="literal">--split-by employee_id</code>. Sqoop cannot currently split on
multi-column indices. If your table has no index column, or has a
multi-column key, then you must also manually choose a splitting
column.</p></div><div class="section" title="7.2.5. Controlling the Import Process"><div class="titlepage"><div><div><h4 class="title"><a name="_controlling_the_import_process"></a>7.2.5. Controlling the Import Process</h4></div></div></div><p>By default, the import process will use JDBC which provides a
reasonable cross-vendor import channel. Some databases can perform
imports in a more high-performance fashion by using database-specific
data movement tools. For example, MySQL provides the <code class="literal">mysqldump</code> tool
which can export data from MySQL to other systems very quickly. By
supplying the <code class="literal">--direct</code> argument, you are specifying that Sqoop
should attempt the direct import channel. This channel may be
higher performance than using JDBC. Currently, direct mode does not
support imports of large object columns.</p><p>When importing from PostgreSQL in conjunction with direct mode, you
can split the import into separate files after
individual files reach a certain size. This size limit is controlled
with the <code class="literal">--direct-split-size</code> argument.</p><p>By default, Sqoop will import a table named <code class="literal">foo</code> to a directory named
<code class="literal">foo</code> inside your home directory in HDFS. For example, if your
username is <code class="literal">someuser</code>, then the import tool will write to
<code class="literal">/user/someuser/foo/(files)</code>. You can adjust the parent directory of
the import with the <code class="literal">--warehouse-dir</code> argument. For example:</p><pre class="screen">$ sqoop import --connnect &lt;connect-str&gt; --table foo --warehouse-dir /shared \
    ...</pre><p>This command would write to a set of files in the <code class="literal">/shared/foo/</code> directory.</p><p>You can also explicitly choose the target directory, like so:</p><pre class="screen">$ sqoop import --connnect &lt;connect-str&gt; --table foo --target-dir /dest \
    ...</pre><p>This will import the files into the <code class="literal">/dest</code> directory. <code class="literal">--target-dir</code> is
incompatible with <code class="literal">--warehouse-dir</code>.</p><p>When using direct mode, you can specify additional arguments which
should be passed to the underlying tool. If the argument
<code class="literal">--</code> is given on the command-line, then subsequent arguments are sent
directly to the underlying tool. For example, the following adjusts
the character set used by <code class="literal">mysqldump</code>:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://server.foo.com/db --table bar \
    --direct -- --default-character-set=latin1</pre><p>By default, imports go to a new target location. If the destination directory
already exists in HDFS, Sqoop will refuse to import and overwrite that
directory&#8217;s contents. If you use the <code class="literal">--append</code> argument, Sqoop will import
data to a temporary directory and then rename the files into the normal
target directory in a manner that does not conflict with existing filenames
in that directory.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>When using the direct mode of import, certain database client utilities
are expected to be present in the shell path of the task process. For MySQL
the utilities <code class="literal">mysqldump</code> and <code class="literal">mysqlimport</code> are required, whereas for
PostgreSQL the utility <code class="literal">psql</code> is required.</p></td></tr></table></div></div><div class="section" title="7.2.6. Controlling type mapping"><div class="titlepage"><div><div><h4 class="title"><a name="_controlling_type_mapping"></a>7.2.6. Controlling type mapping</h4></div></div></div><p>Sqoop is preconfigured to map most SQL types to appropriate Java or Hive
representatives. However the default mapping might not be suitable for
everyone and might be overridden by <code class="literal">--map-column-java</code> (for changing
mapping to Java) or <code class="literal">--map-column-hive</code> (for changing Hive mapping).</p><div class="table"><a name="id384134"></a><p class="title"><b>Table 3. Parameters for overriding mapping</b></p><div class="table-contents"><table summary="Parameters for overriding mapping" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--map-column-java &lt;mapping&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override mapping from SQL to Java type                                  for configured columns.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--map-column-hive &lt;mapping&gt;</code>
    </td><td style="" align="left">
    Override mapping from SQL to Hive type                                  for configured columns.
    </td></tr></tbody></table></div></div><br class="table-break"><p>Sqoop is expecting comma separated list of mapping in form &lt;name of column&gt;=&lt;new type&gt;. For example:</p><pre class="screen">$ sqoop import ... --map-column-java id=String,value=Integer</pre><p>Sqoop will rise exception in case that some configured mapping will not be used.</p></div><div class="section" title="7.2.7. Incremental Imports"><div class="titlepage"><div><div><h4 class="title"><a name="_incremental_imports"></a>7.2.7. Incremental Imports</h4></div></div></div><p>Sqoop provides an incremental import mode which can be used to retrieve
only rows newer than some previously-imported set of rows.</p><p>The following arguments control incremental imports:</p><div class="table"><a name="id384246"></a><p class="title"><b>Table 4. Incremental import arguments:</b></p><div class="table-contents"><table summary="Incremental import arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--check-column (col)</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specifies the column to be examined                               when determining which rows to import.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--incremental (mode)</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specifies how Sqoop determines which                               rows are new. Legal values for <code class="literal">mode</code>                              include <code class="literal">append</code> and <code class="literal">lastmodified</code>.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--last-value (value)</code>
    </td><td style="" align="left">
    Specifies the maximum value of the                               check column from the previous import.
    </td></tr></tbody></table></div></div><br class="table-break"><p>Sqoop supports two types of incremental imports: <code class="literal">append</code> and <code class="literal">lastmodified</code>.
You can use the <code class="literal">--incremental</code> argument to specify the type of incremental
import to perform.</p><p>You should specify <code class="literal">append</code> mode when importing a table where new rows are
continually being added with increasing row id values. You specify the column
containing the row&#8217;s id with <code class="literal">--check-column</code>. Sqoop imports rows where the
check column has a value greater than the one specified with <code class="literal">--last-value</code>.</p><p>An alternate table update strategy supported by Sqoop is called <code class="literal">lastmodified</code>
mode. You should use this when rows of the source table may be updated, and
each such update will set the value of a last-modified column to the current
timestamp.  Rows where the check column holds a timestamp more recent than the
timestamp specified with <code class="literal">--last-value</code> are imported.</p><p>At the end of an incremental import, the value which should be specified as
<code class="literal">--last-value</code> for a subsequent import is printed to the screen. When running
a subsequent import, you should specify <code class="literal">--last-value</code> in this way to ensure
you import only the new or updated data. This is handled automatically by
creating an incremental import as a saved job, which is the preferred
mechanism for performing a recurring incremental import. See the section on
saved jobs later in this document for more information.</p></div><div class="section" title="7.2.8. File Formats"><div class="titlepage"><div><div><h4 class="title"><a name="_file_formats"></a>7.2.8. File Formats</h4></div></div></div><p>You can import data in one of two file formats: delimited text or
SequenceFiles.</p><p>Delimited text is the default import format. You can also specify it
explicitly by using the <code class="literal">--as-textfile</code> argument. This argument will write
string-based representations of each record to the output files, with
delimiter characters between individual columns and rows. These
delimiters may be commas, tabs, or other characters. (The delimiters
can be selected; see "Output line formatting arguments.") The
following is the results of an example text-based import:</p><pre class="screen">1,here is a message,2010-05-01
2,happy new year!,2010-01-01
3,another message,2009-11-12</pre><p>Delimited text is appropriate for most non-binary data types. It also
readily supports further manipulation by other tools, such as Hive.</p><p>SequenceFiles are a binary format that store individual records in
custom record-specific data types. These data types are manifested as
Java classes. Sqoop will automatically generate these data types for
you. This format supports exact storage of all data in binary
representations, and is appropriate for storing binary data
(for example, <code class="literal">VARBINARY</code> columns), or data that will be principly
manipulated by custom MapReduce programs (reading from SequenceFiles
is higher-performance than reading from text files, as records do not
need to be parsed).</p><p>Avro data files are a compact, efficient binary format that provides
interoperability with applications written in other programming
languages.  Avro also supports versioning, so that when, e.g., columns
are added or removed from a table, previously imported data files can
be processed along with new ones.</p><p>By default, data is not compressed. You can compress your data by
using the deflate (gzip) algorithm with the <code class="literal">-z</code> or <code class="literal">--compress</code>
argument, or specify any Hadoop compression codec using the
<code class="literal">--compression-codec</code> argument. This applies to SequenceFile, text,
and Avro files.</p></div><div class="section" title="7.2.9. Large Objects"><div class="titlepage"><div><div><h4 class="title"><a name="_large_objects"></a>7.2.9. Large Objects</h4></div></div></div><p>Sqoop handles large objects (<code class="literal">BLOB</code> and <code class="literal">CLOB</code> columns) in particular
ways. If this data is truly large, then these columns should not be
fully materialized in memory for manipulation, as most columns are.
Instead, their data is handled in a streaming fashion. Large objects
can be stored inline with the rest of the data, in which case they are
fully materialized in memory on every access, or they can be stored in
a secondary storage file linked to the primary data storage. By
default, large objects less than 16 MB in size are stored inline with
the rest of the data. At a larger size, they are stored in files in
the <code class="literal">_lobs</code> subdirectory of the import target directory. These files
are stored in a separate format optimized for large record storage,
which can accomodate records of up to 2^63 bytes each. The size at
which lobs spill into separate files is controlled by the
<code class="literal">--inline-lob-limit</code> argument, which takes a parameter specifying the
largest lob size to keep inline, in bytes. If you set the inline LOB
limit to 0, all large objects will be placed in external
storage.</p><div class="table"><a name="id384575"></a><p class="title"><b>Table 5. Output line formatting arguments:</b></p><div class="table-contents"><table summary="Output line formatting arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field enclosing                                    character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the escape character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the field separator character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the end-of-line character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--mysql-delimiters</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Uses MySQL&#8217;s default delimiter set:                                   fields: <code class="literal">,</code>  lines: <code class="literal">\n</code>                                    escaped-by: <code class="literal">\</code>                                    optionally-enclosed-by: <code class="literal">'</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing character
    </td></tr></tbody></table></div></div><br class="table-break"><p>When importing to delimited files, the choice of delimiter is
important. Delimiters which appear inside string-based fields may
cause ambiguous parsing of the imported data by subsequent analysis
passes. For example, the string <code class="literal">"Hello, pleased to meet you"</code> should
not be imported with the end-of-field delimiter set to a comma.</p><p>Delimiters may be specified as:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
a character (<code class="literal">--fields-terminated-by X</code>)
</li><li class="listitem"><p class="simpara">
an escape character (<code class="literal">--fields-terminated-by \t</code>). Supported escape
  characters are:
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
<code class="literal">\b</code> (backspace)
</li><li class="listitem">
<code class="literal">\n</code> (newline)
</li><li class="listitem">
<code class="literal">\r</code> (carriage return)
</li><li class="listitem">
<code class="literal">\t</code> (tab)
</li><li class="listitem">
<code class="literal">\"</code> (double-quote)
</li><li class="listitem">
<code class="literal">\\'</code> (single-quote)
</li><li class="listitem">
<code class="literal">\\</code> (backslash)
</li><li class="listitem">
<code class="literal">\0</code> (NUL) - This will insert NUL characters between fields or lines,
  or will disable enclosing/escaping if used for one of the <code class="literal">--enclosed-by</code>,
  <code class="literal">--optionally-enclosed-by</code>, or <code class="literal">--escaped-by</code> arguments.
</li></ul></div></li><li class="listitem">
The octal representation of a UTF-8 character&#8217;s code point. This
  should be of the form <code class="literal">\0ooo</code>, where <span class="emphasis"><em>ooo</em></span> is the octal value.
  For example, <code class="literal">--fields-terminated-by \001</code> would yield the <code class="literal">^A</code> character.
</li><li class="listitem">
The hexadecimal representation of a UTF-8 character&#8217;s code point. This
  should be of the form <code class="literal">\0xhhh</code>, where <span class="emphasis"><em>hhh</em></span> is the hex value.
  For example, <code class="literal">--fields-terminated-by \0x10</code> would yield the carriage
  return character.
</li></ul></div><p>The default delimiters are a comma (<code class="literal">,</code>) for fields, a newline (<code class="literal">\n</code>) for records, no quote
character, and no escape character. Note that this can lead to
ambiguous/unparsible records if you import database records containing
commas or newlines in the field data. For unambiguous parsing, both must
be enabled. For example, via <code class="literal">--mysql-delimiters</code>.</p><p>If unambiguous delimiters cannot be presented, then use <span class="emphasis"><em>enclosing</em></span> and
<span class="emphasis"><em>escaping</em></span> characters. The combination of (optional)
enclosing and escaping characters will allow unambiguous parsing of
lines. For example, suppose one column of a dataset contained the
following values:</p><pre class="screen">Some string, with a comma.
Another "string with quotes"</pre><p>The following arguments would provide delimiters which can be
unambiguously parsed:</p><pre class="screen">$ sqoop import --fields-terminated-by , --escaped-by \\ --enclosed-by '\"' ...</pre><p>(Note that to prevent the shell from mangling the enclosing character,
we have enclosed that argument itself in single-quotes.)</p><p>The result of the above arguments applied to the above dataset would
be:</p><pre class="screen">"Some string, with a comma.","1","2","3"...
"Another \"string with quotes\"","4","5","6"...</pre><p>Here the imported strings are shown in the context of additional
columns (<code class="literal">"1","2","3"</code>, etc.) to demonstrate the full effect of enclosing
and escaping. The enclosing character is only strictly necessary when
delimiter characters appear in the imported text. The enclosing
character can therefore be specified as optional:</p><pre class="screen">$ sqoop import --optionally-enclosed-by '\"' (the rest as above)...</pre><p>Which would result in the following import:</p><pre class="screen">"Some string, with a comma.",1,2,3...
"Another \"string with quotes\"",4,5,6...</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Even though Hive supports escaping characters, it does not
handle escaping of new-line character. Also, it does not support
the notion of enclosing characters that may include field delimiters
in the enclosed string.  It is therefore recommended that you choose
unambiguous field and record-terminating delimiters without the help
of escaping and enclosing characters when working with Hive; this is
due to limitations of Hive&#8217;s input parsing abilities.</p></td></tr></table></div><p>The <code class="literal">--mysql-delimiters</code> argument is a shorthand argument which uses
the default delimiters for the <code class="literal">mysqldump</code> program.
If you use the <code class="literal">mysqldump</code> delimiters in conjunction with a
direct-mode import (with <code class="literal">--direct</code>), very fast imports can be
achieved.</p><p>While the choice of delimiters is most important for a text-mode
import, it is still relevant if you import to SequenceFiles with
<code class="literal">--as-sequencefile</code>. The generated class' <code class="literal">toString()</code> method
will use the delimiters you specify, so subsequent formatting of
the output data will rely on the delimiters you choose.</p><div class="table"><a name="id385097"></a><p class="title"><b>Table 6. Input parsing arguments:</b></p><div class="table-contents"><table summary="Input parsing arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field encloser
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input escape                                          character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input field separator
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input end-of-line                                          character
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--input-optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing                                          character
    </td></tr></tbody></table></div></div><br class="table-break"><p>When Sqoop imports data to HDFS, it generates a Java class which can
reinterpret the text files that it creates when doing a
delimited-format import. The delimiters are chosen with arguments such
as <code class="literal">--fields-terminated-by</code>; this controls both how the data is
written to disk, and how the generated <code class="literal">parse()</code> method reinterprets
this data. The delimiters used by the <code class="literal">parse()</code> method can be chosen
independently of the output arguments, by using
<code class="literal">--input-fields-terminated-by</code>, and so on. This is useful, for example, to
generate classes which can parse records created with one set of
delimiters, and emit the records to a different set of files using a
separate set of delimiters.</p><div class="table"><a name="id385259"></a><p class="title"><b>Table 7. Hive arguments:</b></p><div class="table-contents"><table summary="Hive arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override <code class="literal">$HIVE_HOME</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-import</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Import tables into Hive (Uses Hive&#8217;s                               default delimiters if none are set.)
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-overwrite</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Overwrite existing data in the Hive table.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--create-hive-table</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    If set, then the job will fail if the target hive
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    table exits. By default this property is false.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-table &lt;table-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the table name to use when importing                              to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-drop-import-delims</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Drops <span class="emphasis"><em>\n</em></span>, <span class="emphasis"><em>\r</em></span>, and <span class="emphasis"><em>\01</em></span> from string                              fields when importing to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-delims-replacement</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Replace <span class="emphasis"><em>\n</em></span>, <span class="emphasis"><em>\r</em></span>, and <span class="emphasis"><em>\01</em></span> from string                              fields with user defined string when importing to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-partition-key</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Name of a hive field to partition are                               sharded on
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-partition-value &lt;v&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    String-value that serves as partition key                              for this imported into hive in this job.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--map-column-hive &lt;map&gt;</code>
    </td><td style="" align="left">
    Override default mapping from SQL type to                              Hive type for configured columns.
    </td></tr></tbody></table></div></div><br class="table-break"></div><div class="section" title="7.2.10. Importing Data Into Hive"><div class="titlepage"><div><div><h4 class="title"><a name="_importing_data_into_hive"></a>7.2.10. Importing Data Into Hive</h4></div></div></div><p>Sqoop&#8217;s import tool&#8217;s main function is to upload your data into files
in HDFS. If you have a Hive metastore associated with your HDFS
cluster, Sqoop can also import the data into Hive by generating and
executing a <code class="literal">CREATE TABLE</code> statement to define the data&#8217;s layout in
Hive. Importing data into Hive is as simple as adding the
<span class="strong"><strong><code class="literal">--hive-import</code></strong></span> option to your Sqoop command line.</p><p>If the Hive table already exists, you can specify the
<span class="strong"><strong><code class="literal">--hive-overwrite</code></strong></span> option to indicate that existing table in hive must
be replaced. After your data is imported into HDFS or this step is
omitted, Sqoop will generate a Hive script containing a <code class="literal">CREATE TABLE</code>
operation defining your columns using Hive&#8217;s types, and a <code class="literal">LOAD DATA INPATH</code>
statement to move the data files into Hive&#8217;s warehouse directory.</p><p>The script will be executed by calling
the installed copy of hive on the machine where Sqoop is run. If you have
multiple Hive installations, or <code class="literal">hive</code> is not in your <code class="literal">$PATH</code>, use the
<span class="strong"><strong><code class="literal">--hive-home</code></strong></span> option to identify the Hive installation directory.
Sqoop will use <code class="literal">$HIVE_HOME/bin/hive</code> from here.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>This function is incompatible with <code class="literal">--as-avrodatafile</code> and
<code class="literal">--as-sequencefile</code>.</p></td></tr></table></div><p>Even though Hive supports escaping characters, it does not
handle escaping of new-line character. Also, it does not support
the notion of enclosing characters that may include field delimiters
in the enclosed string.  It is therefore recommended that you choose
unambiguous field and record-terminating delimiters without the help
of escaping and enclosing characters when working with Hive; this is
due to limitations of Hive&#8217;s input parsing abilities. If you do use
<code class="literal">--escaped-by</code>, <code class="literal">--enclosed-by</code>, or <code class="literal">--optionally-enclosed-by</code> when
importing data into Hive, Sqoop will print a warning message.</p><p>Hive will have problems using Sqoop-imported data if your database&#8217;s
rows contain string fields that have Hive&#8217;s default row delimiters
(<code class="literal">\n</code> and <code class="literal">\r</code> characters) or column delimiters (<code class="literal">\01</code> characters)
present in them.  You can use the <code class="literal">--hive-drop-import-delims</code> option
to drop those characters on import to give Hive-compatible text data.
Alternatively, you can use the <code class="literal">--hive-delims-replacement</code> option
to replace those characters with a user-defined string on import to give
Hive-compatible text data.  These options should only be used if you use
Hive&#8217;s default delimiters and should not be used if different delimiters
are specified.</p><p>Sqoop will pass the field and record delimiters through to Hive. If you do
not set any delimiters and do use <code class="literal">--hive-import</code>, the field delimiter will
be set to <code class="literal">^A</code> and the record delimiter will be set to <code class="literal">\n</code> to be consistent
with Hive&#8217;s defaults.</p><p>The table name used in Hive is, by default, the same as that of the
source table. You can control the output table name with the <code class="literal">--hive-table</code>
option.</p><p>Hive can put data into partitions for more efficient query
performance.  You can tell a Sqoop job to import data for Hive into a
particular partition by specifying the <code class="literal">--hive-partition-key</code> and
<code class="literal">--hive-partition-value</code> arguments.  The partition value must be a
string.  Please see the Hive documentation for more details on
partitioning.</p><p>You can import compressed tables into Hive using the <code class="literal">--compress</code> and
<code class="literal">--compression-codec</code> options. One downside to compressing tables imported
into Hive is that many codecs cannot be split for processing by parallel map
tasks. The lzop codec, however, does support splitting. When importing tables
with this codec, Sqoop will automatically index the files for splitting and
configuring a new Hive table with the correct InputFormat. This feature
currently requires that all partitions of a table be compressed with the lzop
codec.</p><div class="table"><a name="id385739"></a><p class="title"><b>Table 8. HBase arguments:</b></p><div class="table-contents"><table summary="HBase arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--column-family &lt;family&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the target column family for the import
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hbase-create-table</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    If specified, create missing HBase tables
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hbase-row-key &lt;col&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specifies which input column to use as the                              row key
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--hbase-table &lt;table-name&gt;</code>
    </td><td style="" align="left">
    Specifies an HBase table to use as the                               target instead of HDFS
    </td></tr></tbody></table></div></div><br class="table-break"></div><div class="section" title="7.2.11. Importing Data Into HBase"><div class="titlepage"><div><div><h4 class="title"><a name="_importing_data_into_hbase"></a>7.2.11. Importing Data Into HBase</h4></div></div></div><p>Sqoop supports additional import targets beyond HDFS and Hive. Sqoop
can also import records into a table in HBase.</p><p>By specifying <code class="literal">--hbase-table</code>, you instruct Sqoop to import
to a table in HBase rather than a directory in HDFS. Sqoop will
import data to the table specified as the argument to <code class="literal">--hbase-table</code>.
Each row of the input table will be transformed into an HBase
<code class="literal">Put</code> operation to a row of the output table. The key for each row is
taken from a column of the input. By default Sqoop will use the split-by
column as the row key column. If that is not specified, it will try to
identify the primary key column, if any, of the source table. You can
manually specify the row key column with <code class="literal">--hbase-row-key</code>. Each output
column will be placed in the same column family, which must be specified
with <code class="literal">--column-family</code>.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>This function is incompatible with direct import (parameter
<code class="literal">--direct</code>).</p></td></tr></table></div><p>If the target table and column family do not exist, the Sqoop job will
exit with an error. You should create the target table and column family
before running an import. If you specify <code class="literal">--hbase-create-table</code>, Sqoop
will create the target table and column family if they do not exist,
using the default parameters from your HBase configuration.</p><p>Sqoop currently serializes all values to HBase by converting each field
to its string representation (as if you were importing to HDFS in text
mode), and then inserts the UTF-8 bytes of this string in the target
cell.</p><div class="table"><a name="id385934"></a><p class="title"><b>Table 9. Code generation arguments:</b></p><div class="table-contents"><table summary="Code generation arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--bindir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Output directory for compiled objects
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--class-name &lt;name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the generated class name. This overrides                         <code class="literal">--package-name</code>. When combined with                          <code class="literal">--jar-file</code>, sets the input class.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--jar-file &lt;file&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Disable code generation; use specified jar
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--outdir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Output directory for generated code
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--package-name &lt;name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Put auto-generated classes in this package
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--map-column-java &lt;m&gt;</code>
    </td><td style="" align="left">
    Override default mapping from SQL type to                         Java type for configured columns.
    </td></tr></tbody></table></div></div><br class="table-break"><p>As mentioned earlier, a byproduct of importing a table to HDFS is a
class which can manipulate the imported data. If the data is stored in
SequenceFiles, this class will be used for the data&#8217;s serialization
container. Therefore, you should use this class in your subsequent
MapReduce processing of the data.</p><p>The class is typically named after the table; a table named <code class="literal">foo</code> will
generate a class named <code class="literal">foo</code>. You may want to override this class
name. For example, if your table is named <code class="literal">EMPLOYEES</code>, you may want to
specify <code class="literal">--class-name Employee</code> instead. Similarly, you can specify
just the package name with <code class="literal">--package-name</code>. The following import
generates a class named <code class="literal">com.foocorp.SomeTable</code>:</p><pre class="screen">$ sqoop import --connect &lt;connect-str&gt; --table SomeTable --package-name com.foocorp</pre><p>The <code class="literal">.java</code> source file for your class will be written to the current
working directory when you run <code class="literal">sqoop</code>. You can control the output
directory with <code class="literal">--outdir</code>. For example, <code class="literal">--outdir src/generated/</code>.</p><p>The import process compiles the source into <code class="literal">.class</code> and <code class="literal">.jar</code> files;
these are ordinarily stored under <code class="literal">/tmp</code>. You can select an alternate
target directory with <code class="literal">--bindir</code>. For example, <code class="literal">--bindir /scratch</code>.</p><p>If you already have a compiled class that can be used to perform the
import and want to suppress the code-generation aspect of the import
process, you can use an existing jar and class by
providing the <code class="literal">--jar-file</code> and <code class="literal">--class-name</code> options. For example:</p><pre class="screen">$ sqoop import --table SomeTable --jar-file mydatatypes.jar \
    --class-name SomeTableType</pre><p>This command will load the <code class="literal">SomeTableType</code> class out of <code class="literal">mydatatypes.jar</code>.</p></div></div><div class="section" title="7.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations"></a>7.3. Example Invocations</h3></div></div></div><p>The following examples illustrate how to use the import tool in a variety
of situations.</p><p>A basic import of a table named <code class="literal">EMPLOYEES</code> in the <code class="literal">corp</code> database:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES</pre><p>A basic import requiring a login:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    --username SomeUser -P
Enter password: (hidden)</pre><p>Selecting specific columns from the <code class="literal">EMPLOYEES</code> table:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    --columns "employee_id,first_name,last_name,job_title"</pre><p>Controlling the import parallelism (using 8 parallel tasks):</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    -m 8</pre><p>Enabling the MySQL "direct mode" fast path:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    --direct</pre><p>Storing data in SequenceFiles, and setting the generated class name to
<code class="literal">com.foocorp.Employee</code>:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    --class-name com.foocorp.Employee --as-sequencefile</pre><p>Specifying the delimiters to use in a text-mode import:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    --fields-terminated-by '\t' --lines-terminated-by '\n' \
    --optionally-enclosed-by '\"'</pre><p>Importing the data to Hive:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    --hive-import</pre><p>Importing only new employees:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    --where "start_date &gt; '2010-01-01'"</pre><p>Changing the splitting column from the default:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES \
    --split-by dept_id</pre><p>Verifying that an import was successful:</p><pre class="screen">$ hadoop fs -ls EMPLOYEES
Found 5 items
drwxr-xr-x   - someuser somegrp          0 2010-04-27 16:40 /user/someuser/EMPLOYEES/_logs
-rw-r--r--   1 someuser somegrp    2913511 2010-04-27 16:40 /user/someuser/EMPLOYEES/part-m-00000
-rw-r--r--   1 someuser somegrp    1683938 2010-04-27 16:40 /user/someuser/EMPLOYEES/part-m-00001
-rw-r--r--   1 someuser somegrp    7245839 2010-04-27 16:40 /user/someuser/EMPLOYEES/part-m-00002
-rw-r--r--   1 someuser somegrp    7842523 2010-04-27 16:40 /user/someuser/EMPLOYEES/part-m-00003

$ hadoop fs -cat EMPLOYEES/part-m-00000 | head -n 10
0,joe,smith,engineering
1,jane,doe,marketing
...</pre><p>Performing an incremental import of new data, after having already
imported the first 100,000 rows of a table:</p><pre class="screen">$ sqoop import --connect jdbc:mysql://db.foo.com/somedb --table sometable \
    --where "id &gt; 100000" --target-dir /incremental_dataset --append</pre></div></div><div class="section" title="8. sqoop-import-all-tables"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_import_all_tables_literal"></a>8. <code class="literal">sqoop-import-all-tables</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_2">8.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_2">8.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_2">8.3. Example Invocations</a></span></dt></dl></div><div class="section" title="8.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_2"></a>8.1. Purpose</h3></div></div></div><p>The <code class="literal">import-all-tables</code> tool imports a set of tables from an RDBMS to HDFS.
Data from each table is stored in a separate directory in HDFS.</p><p>For the <code class="literal">import-all-tables</code> tool to be useful, the following conditions
must be met:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Each table must have a single-column primary key.
</li><li class="listitem">
You must intend to import all columns of each table.
</li><li class="listitem">
You must not intend to use non-default splitting column, nor impose
  any conditions via a <code class="literal">WHERE</code> clause.
</li></ul></div></div><div class="section" title="8.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_2"></a>8.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop import-all-tables (generic-args) (import-args)
$ sqoop-import-all-tables (generic-args) (import-args)</pre><p>Although the Hadoop generic arguments must preceed any import arguments,
the import arguments can be entered in any order with respect to one
another.</p><div class="table"><a name="id386497"></a><p class="title"><b>Table 10. Common arguments</b></p><div class="table-contents"><table summary="Common arguments" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connect &lt;jdbc-uri&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify JDBC connect string
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connection-manager &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify connection manager class to                                          use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--driver &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Manually specify JDBC driver class                                          to use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hadoop-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override $HADOOP_HOME
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-P</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Read password from console
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--password &lt;password&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication password
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--username &lt;username&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication username
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print more information while working
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--connection-param-file &lt;filename&gt;</code>
    </td><td style="" align="left">
    Optional properties file that                                          provides connection parameters
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id386703"></a><p class="title"><b>Table 11. Import control arguments:</b></p><div class="table-contents"><table summary="Import control arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--as-avrodatafile</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Imports data to Avro Data Files
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--as-sequencefile</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Imports data to SequenceFiles
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--as-textfile</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Imports data as plain text (default)
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--direct</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Use direct import fast path
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--direct-split-size &lt;n&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Split the input stream every <span class="emphasis"><em>n</em></span> bytes when                             importing in direct mode
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--inline-lob-limit &lt;n&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set the maximum size for an inline LOB
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-m,--num-mappers &lt;n&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Use <span class="emphasis"><em>n</em></span> map tasks to import in parallel
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--warehouse-dir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    HDFS parent for table destination
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-z,--compress</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Enable compression
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--compression-codec &lt;c&gt;</code>
    </td><td style="" align="left">
    Use Hadoop codec (default gzip)
    </td></tr></tbody></table></div></div><br class="table-break"><p>These arguments behave in the same manner as they do when used for the
<code class="literal">sqoop-import</code> tool, but the <code class="literal">--table</code>, <code class="literal">--split-by</code>, <code class="literal">--columns</code>,
and <code class="literal">--where</code> arguments are invalid for <code class="literal">sqoop-import-all-tables</code>.</p><div class="table"><a name="id386950"></a><p class="title"><b>Table 12. Output line formatting arguments:</b></p><div class="table-contents"><table summary="Output line formatting arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field enclosing                                    character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the escape character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the field separator character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the end-of-line character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--mysql-delimiters</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Uses MySQL&#8217;s default delimiter set:                                   fields: <code class="literal">,</code>  lines: <code class="literal">\n</code>                                    escaped-by: <code class="literal">\</code>                                    optionally-enclosed-by: <code class="literal">'</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing character
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id387115"></a><p class="title"><b>Table 13. Input parsing arguments:</b></p><div class="table-contents"><table summary="Input parsing arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field encloser
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input escape                                          character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input field separator
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input end-of-line                                          character
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--input-optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing                                          character
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id387245"></a><p class="title"><b>Table 14. Hive arguments:</b></p><div class="table-contents"><table summary="Hive arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override <code class="literal">$HIVE_HOME</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-import</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Import tables into Hive (Uses Hive&#8217;s                               default delimiters if none are set.)
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-overwrite</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Overwrite existing data in the Hive table.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--create-hive-table</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    If set, then the job will fail if the target hive
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    table exits. By default this property is false.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-table &lt;table-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the table name to use when importing                              to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-drop-import-delims</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Drops <span class="emphasis"><em>\n</em></span>, <span class="emphasis"><em>\r</em></span>, and <span class="emphasis"><em>\01</em></span> from string                              fields when importing to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-delims-replacement</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Replace <span class="emphasis"><em>\n</em></span>, <span class="emphasis"><em>\r</em></span>, and <span class="emphasis"><em>\01</em></span> from string                              fields with user defined string when importing to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-partition-key</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Name of a hive field to partition are                               sharded on
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-partition-value &lt;v&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    String-value that serves as partition key                              for this imported into hive in this job.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--map-column-hive &lt;map&gt;</code>
    </td><td style="" align="left">
    Override default mapping from SQL type to                              Hive type for configured columns.
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id387491"></a><p class="title"><b>Table 15. Code generation arguments:</b></p><div class="table-contents"><table summary="Code generation arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--bindir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Output directory for compiled objects
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--jar-file &lt;file&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Disable code generation; use specified jar
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--outdir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Output directory for generated code
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--package-name &lt;name&gt;</code>
    </td><td style="" align="left">
    Put auto-generated classes in this package
    </td></tr></tbody></table></div></div><br class="table-break"><p>The <code class="literal">import-all-tables</code> tool does not support the <code class="literal">--class-name</code> argument.
You may, however, specify a package with <code class="literal">--package-name</code> in which all
generated classes will be placed.</p></div><div class="section" title="8.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_2"></a>8.3. Example Invocations</h3></div></div></div><p>Import all tables from the <code class="literal">corp</code> database:</p><pre class="screen">$ sqoop import-all-tables --connect jdbc:mysql://db.foo.com/corp</pre><p>Verifying that it worked:</p><pre class="screen">$ hadoop fs -ls
Found 4 items
drwxr-xr-x   - someuser somegrp       0 2010-04-27 17:15 /user/someuser/EMPLOYEES
drwxr-xr-x   - someuser somegrp       0 2010-04-27 17:15 /user/someuser/PAYCHECKS
drwxr-xr-x   - someuser somegrp       0 2010-04-27 17:15 /user/someuser/DEPARTMENTS
drwxr-xr-x   - someuser somegrp       0 2010-04-27 17:15 /user/someuser/OFFICE_SUPPLIES</pre></div></div><div class="section" title="9. sqoop-export"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_export_literal"></a>9. <code class="literal">sqoop-export</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_3">9.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_3">9.2. Syntax</a></span></dt><dt><span class="section"><a href="#_inserts_vs_updates">9.3. Inserts vs. Updates</a></span></dt><dt><span class="section"><a href="#_exports_and_transactions">9.4. Exports and Transactions</a></span></dt><dt><span class="section"><a href="#_failed_exports">9.5. Failed Exports</a></span></dt><dt><span class="section"><a href="#_example_invocations_3">9.6. Example Invocations</a></span></dt></dl></div><div class="section" title="9.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_3"></a>9.1. Purpose</h3></div></div></div><p>The <code class="literal">export</code> tool exports a set of files from HDFS back to an RDBMS.
The target table must already exist in the database. The input files
are read and parsed into a set of records according to the
user-specified delimiters.</p><p>The default operation is to transform these into a set of <code class="literal">INSERT</code>
statements that inject the records into the database. In "update mode,"
Sqoop will generate <code class="literal">UPDATE</code> statements that replace existing records
in the database.</p></div><div class="section" title="9.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_3"></a>9.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop export (generic-args) (export-args)
$ sqoop-export (generic-args) (export-args)</pre><p>Although the Hadoop generic arguments must preceed any export arguments,
the export arguments can be entered in any order with respect to one
another.</p><div class="table"><a name="id387729"></a><p class="title"><b>Table 16. Common arguments</b></p><div class="table-contents"><table summary="Common arguments" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connect &lt;jdbc-uri&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify JDBC connect string
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connection-manager &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify connection manager class to                                          use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--driver &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Manually specify JDBC driver class                                          to use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hadoop-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override $HADOOP_HOME
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-P</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Read password from console
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--password &lt;password&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication password
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--username &lt;username&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication username
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print more information while working
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--connection-param-file &lt;filename&gt;</code>
    </td><td style="" align="left">
    Optional properties file that                                          provides connection parameters
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id387936"></a><p class="title"><b>Table 17. Export control arguments:</b></p><div class="table-contents"><table summary="Export control arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--direct</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Use direct export fast path
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--export-dir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    HDFS source path for the export
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-m,--num-mappers &lt;n&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Use <span class="emphasis"><em>n</em></span> map tasks to export in                                         parallel
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--table &lt;table-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Table to populate
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--update-key &lt;col-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Anchor column to use for updates.                                         Use a comma separated list of columns                                         if there are more than one column.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--update-mode &lt;mode&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify how updates are performed                                         when new rows are found with                                         non-matching keys in database.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Legal values for <code class="literal">mode</code> include                                         <code class="literal">updateonly</code> (default) and                                         <code class="literal">allowinsert</code>.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-null-string &lt;null-string&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    The string to be interpreted as                                         null for string columns
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-null-non-string &lt;null-string&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    The string to be interpreted as                                         null for non-string columns
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--staging-table &lt;staging-table-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    The table in which data will be                                         staged before being inserted into                                         the destination table.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--clear-staging-table</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Indicates that any data present in                                         the staging table can be deleted.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--batch</code>
    </td><td style="" align="left">
    Use batch mode for underlying                                         statement execution.
    </td></tr></tbody></table></div></div><br class="table-break"><p>The <code class="literal">--table</code> and <code class="literal">--export-dir</code> arguments are required. These
specify the table to populate in the database, and the
directory in HDFS that contains the source data.</p><p>You can control the number of mappers independently from the number of
files present in the directory. Export performance depends on the
degree of parallelism. By default, Sqoop will use four tasks in
parallel for the export process. This may not be optimal; you will
need to experiment with your own particular setup. Additional tasks
may offer better concurrency, but if the database is already
bottlenecked on updating indices, invoking triggers, and so on, then
additional load may decrease performance. The <code class="literal">--num-mappers</code> or <code class="literal">-m</code>
arguments control the number of map tasks, which is the degree of
parallelism used.</p><p>MySQL provides a direct mode for exports as well, using the
<code class="literal">mysqlimport</code> tool. When exporting to MySQL, use the <code class="literal">--direct</code> argument
to specify this codepath. This may be
higher-performance than the standard JDBC codepath.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>When using export in direct mode with MySQL, the MySQL bulk utility
<code class="literal">mysqlimport</code> must be available in the shell path of the task process.</p></td></tr></table></div><p>The <code class="literal">--input-null-string</code> and <code class="literal">--input-null-non-string</code> arguments are
optional. If <code class="literal">--input-null-string</code> is not specified, then the string
"null" will be interpreted as null for string-type columns.
If <code class="literal">--input-null-non-string</code> is not specified, then both the string
"null" and the empty string will be interpreted as null for non-string
columns. Note that, the empty string will be always interpreted as null
for non-string columns, in addition to other string if specified by
<code class="literal">--input-null-non-string</code>.</p><p>Since Sqoop breaks down export process into multiple transactions, it
is possible that a failed export job may result in partial data being
committed to the database. This can further lead to subsequent jobs
failing due to insert collisions in some cases, or lead to duplicated data
in others. You can overcome this problem by specifying a staging table via
the <code class="literal">--staging-table</code> option which acts as an auxiliary table that is used
to stage exported data. The staged data is finally moved to the destination
table in a single transaction.</p><p>In order to use the staging facility, you must create the staging table
prior to running the export job. This table must be structurally
identical to the target table. This table should either be empty before
the export job runs, or the <code class="literal">--clear-staging-table</code> option must be specified.
If the staging table contains data and the <code class="literal">--clear-staging-table</code> option is
specified, Sqoop will delete all of the data before starting the export job.</p><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>Support for staging data prior to pushing it into the destination
table is not available for <code class="literal">--direct</code> exports. It is also not available when
export is invoked using the <code class="literal">--update-key</code> option for updating existing data.</p></td></tr></table></div></div><div class="section" title="9.3. Inserts vs. Updates"><div class="titlepage"><div><div><h3 class="title"><a name="_inserts_vs_updates"></a>9.3. Inserts vs. Updates</h3></div></div></div><p>By default, <code class="literal">sqoop-export</code> appends new rows to a table; each input
record is transformed into an <code class="literal">INSERT</code> statement that adds a row to the
target database table. If your table has constraints (e.g., a primary
key column whose values must be unique) and already contains data, you
must take care to avoid inserting records that violate these
constraints. The export process will fail if an <code class="literal">INSERT</code> statement
fails. This mode is primarily intended for exporting records to a new,
empty table intended to receive these results.</p><p>If you specify the <code class="literal">--update-key</code> argument, Sqoop will instead modify
an existing dataset in the database. Each input record is treated as
an <code class="literal">UPDATE</code> statement that modifies an existing row. The row a
statement modifies is determined by the column name(s) specified with
<code class="literal">--update-key</code>. For example, consider the following table
definition:</p><pre class="screen">CREATE TABLE foo(
    id INT NOT NULL PRIMARY KEY,
    msg VARCHAR(32),
    bar INT);</pre><p>Consider also a dataset in HDFS containing records like these:</p><pre class="screen">0,this is a test,42
1,some more data,100
...</pre><p>Running <code class="literal">sqoop-export --table foo --update-key id --export-dir
/path/to/data --connect &#8230;</code> will run an export job that executes SQL
statements based on the data like so:</p><pre class="screen">UPDATE foo SET msg='this is a test', bar=42 WHERE id=0;
UPDATE foo SET msg='some more data', bar=100 WHERE id=1;
...</pre><p>If an <code class="literal">UPDATE</code> statement modifies no rows, this is not considered an
error; the export will silently continue. (In effect, this means that
an update-based export will not insert new rows into the database.)
Likewise, if the column specified with <code class="literal">--update-key</code> does not
uniquely identify rows and multiple rows are updated by a single
statement, this condition is also undetected.</p><p>The argument <code class="literal">--update-key</code> can also be given a comma separated list of
column names. In which case, Sqoop will match all keys from this list before
updating any existing record.</p><p>Depending on the target database, you may also specify the <code class="literal">--update-mode</code>
argument with <code class="literal">allowinsert</code> mode if you want to update rows if they exist
in the database already or insert rows if they do not exist yet.</p><div class="table"><a name="id388488"></a><p class="title"><b>Table 18. Input parsing arguments:</b></p><div class="table-contents"><table summary="Input parsing arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field encloser
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input escape                                          character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input field separator
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input end-of-line                                          character
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--input-optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing                                          character
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id388618"></a><p class="title"><b>Table 19. Output line formatting arguments:</b></p><div class="table-contents"><table summary="Output line formatting arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field enclosing                                    character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the escape character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the field separator character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the end-of-line character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--mysql-delimiters</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Uses MySQL&#8217;s default delimiter set:                                   fields: <code class="literal">,</code>  lines: <code class="literal">\n</code>                                    escaped-by: <code class="literal">\</code>                                    optionally-enclosed-by: <code class="literal">'</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing character
    </td></tr></tbody></table></div></div><br class="table-break"><p>Sqoop automatically generates code to parse and interpret records of the
files containing the data to be exported back to the database. If
these files were created with non-default delimiters (comma-separated
fields with newline-separated records), you should specify
the same delimiters again so that Sqoop can parse your files.</p><p>If you specify incorrect delimiters, Sqoop will fail to find enough
columns per line. This will cause export map tasks to fail by throwing
<code class="literal">ParseExceptions</code>.</p><div class="table"><a name="id388803"></a><p class="title"><b>Table 20. Code generation arguments:</b></p><div class="table-contents"><table summary="Code generation arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--bindir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Output directory for compiled objects
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--class-name &lt;name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the generated class name. This overrides                         <code class="literal">--package-name</code>. When combined with                          <code class="literal">--jar-file</code>, sets the input class.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--jar-file &lt;file&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Disable code generation; use specified jar
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--outdir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Output directory for generated code
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--package-name &lt;name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Put auto-generated classes in this package
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--map-column-java &lt;m&gt;</code>
    </td><td style="" align="left">
    Override default mapping from SQL type to                         Java type for configured columns.
    </td></tr></tbody></table></div></div><br class="table-break"><p>If the records to be exported were generated as the result of a
previous import, then the original generated class can be used to read
the data back. Specifying <code class="literal">--jar-file</code> and <code class="literal">--class-name</code> obviate
the need to specify delimiters in this case.</p><p>The use of existing generated code is incompatible with
<code class="literal">--update-key</code>; an update-mode export requires new code generation to
perform the update. You cannot use <code class="literal">--jar-file</code>, and must fully specify
any non-default delimiters.</p></div><div class="section" title="9.4. Exports and Transactions"><div class="titlepage"><div><div><h3 class="title"><a name="_exports_and_transactions"></a>9.4. Exports and Transactions</h3></div></div></div><p>Exports are performed by multiple writers in parallel. Each writer
uses a separate connection to the database; these have separate
transactions from one another. Sqoop uses the multi-row <code class="literal">INSERT</code>
syntax to insert up to 100 records per statement. Every 100
statements, the current transaction within a writer task is committed,
causing a commit every 10,000 rows. This ensures that transaction
buffers do not grow without bound, and cause out-of-memory conditions.
Therefore, an export is not an atomic process. Partial results from
the export will become visible before the export is complete.</p></div><div class="section" title="9.5. Failed Exports"><div class="titlepage"><div><div><h3 class="title"><a name="_failed_exports"></a>9.5. Failed Exports</h3></div></div></div><p>Exports may fail for a number of reasons:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Loss of connectivity from the Hadoop cluster to the database (either
  due to hardware fault, or server software crashes)
</li><li class="listitem">
Attempting to <code class="literal">INSERT</code> a row which violates a consistency constraint
  (for example, inserting a duplicate primary key value)
</li><li class="listitem">
Attempting to parse an incomplete or malformed record from the HDFS
  source data
</li><li class="listitem">
Attempting to parse records using incorrect delimiters
</li><li class="listitem">
Capacity issues (such as insufficient RAM or disk space)
</li></ul></div><p>If an export map task fails due to these or other reasons, it will
cause the export job to fail. The results of a failed export are
undefined. Each export map task operates in a separate transaction.
Furthermore, individual map tasks <code class="literal">commit</code> their current transaction
periodically. If a task fails, the current transaction will be rolled
back. Any previously-committed transactions will remain durable in the
database, leading to a partially-complete export.</p></div><div class="section" title="9.6. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_3"></a>9.6. Example Invocations</h3></div></div></div><p>A basic export to populate a table named <code class="literal">bar</code>:</p><pre class="screen">$ sqoop export --connect jdbc:mysql://db.example.com/foo --table bar  \
    --export-dir /results/bar_data</pre><p>This example takes the files in <code class="literal">/results/bar_data</code> and injects their
contents in to the <code class="literal">bar</code> table in the <code class="literal">foo</code> database on <code class="literal">db.example.com</code>.
The target table must already exist in the database. Sqoop performs
a set of <code class="literal">INSERT INTO</code> operations, without regard for existing content. If
Sqoop attempts to insert rows which violate constraints in the database
(for example, a particular primary key value already exists), then the export
fails.</p></div></div><div class="section" title="10. Saved Jobs"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_saved_jobs"></a>10. Saved Jobs</h2></div></div></div><p>Imports and exports can be repeatedly performed by issuing the same command
multiple times. Especially when using the incremental import capability,
this is an expected scenario.</p><p>Sqoop allows you to define <span class="emphasis"><em>saved jobs</em></span> which make this process easier. A
saved job records the configuration information required to execute a
Sqoop command at a later time. The section on the <code class="literal">sqoop-job</code> tool
describes how to create and work with saved jobs.</p><p>By default, job descriptions are saved to a private repository stored
in <code class="literal">$HOME/.sqoop/</code>. You can configure Sqoop to instead use a shared
<span class="emphasis"><em>metastore</em></span>, which makes saved jobs available to multiple users across a
shared cluster. Starting the metastore is covered by the section on the
<code class="literal">sqoop-metastore</code> tool.</p></div><div class="section" title="11. sqoop-job"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_job_literal"></a>11. <code class="literal">sqoop-job</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_4">11.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_4">11.2. Syntax</a></span></dt><dt><span class="section"><a href="#_saved_jobs_and_passwords">11.3. Saved jobs and passwords</a></span></dt><dt><span class="section"><a href="#_saved_jobs_and_incremental_imports">11.4. Saved jobs and incremental imports</a></span></dt></dl></div><div class="section" title="11.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_4"></a>11.1. Purpose</h3></div></div></div><p>The job tool allows you to create and work with saved jobs. Saved jobs
remember the parameters used to specify a job, so they can be
re-executed by invoking the job by its handle.</p><p>If a saved job is configured to perform an incremental import, state regarding
the most recently imported rows is updated in the saved job to allow the job
to continually import only the newest rows.</p></div><div class="section" title="11.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_4"></a>11.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop job (generic-args) (job-args) [-- [subtool-name] (subtool-args)]
$ sqoop-job (generic-args) (job-args) [-- [subtool-name] (subtool-args)]</pre><p>Although the Hadoop generic arguments must preceed any job arguments,
the job arguments can be entered in any order with respect to one
another.</p><div class="table"><a name="id389252"></a><p class="title"><b>Table 21. Job management options:</b></p><div class="table-contents"><table summary="Job management options:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--create &lt;job-id&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Define a new saved job with the specified                             job-id (name). A second Sqoop                             command-line, separated by a <code class="literal">--</code> should                             be specified; this defines the saved job.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--delete &lt;job-id&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Delete a saved job.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--exec &lt;job-id&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Given a job defined with <code class="literal">--create</code>, run                             the saved job.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--show &lt;job-id&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Show the parameters for a saved job.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--list</code>
    </td><td style="" align="left">
    List all saved jobs
    </td></tr></tbody></table></div></div><br class="table-break"><p>Creating saved jobs is done with the <code class="literal">--create</code> action. This operation
requires a <code class="literal">--</code> followed by a tool name and its arguments. The tool and
its arguments will form the basis of the saved job. Consider:</p><pre class="screen">$ sqoop job --create myjob -- import --connect jdbc:mysql://example.com/db \
    --table mytable</pre><p>This creates a job named <code class="literal">myjob</code> which can be executed later. The job is not
run. This job is now available in the list of saved jobs:</p><pre class="screen">$ sqoop job --list
Available jobs:
  myjob</pre><p>We can inspect the configuration of a job with the <code class="literal">show</code> action:</p><pre class="screen"> $ sqoop job --show myjob
 Job: myjob
 Tool: import
 Options:
 ----------------------------
 direct.import = false
 codegen.input.delimiters.record = 0
 hdfs.append.dir = false
 db.table = mytable
 ...</pre><p>And if we are satisfied with it, we can run the job with <code class="literal">exec</code>:</p><pre class="screen">$ sqoop job --exec myjob
10/08/19 13:08:45 INFO tool.CodeGenTool: Beginning code generation
...</pre><p>The <code class="literal">exec</code> action allows you to override arguments of the saved job
by supplying them after a <code class="literal">--</code>. For example, if the database were
changed to require a username, we could specify the username and
password with:</p><pre class="screen">$ sqoop job --exec myjob -- --username someuser -P
Enter password:
...</pre><div class="table"><a name="id389484"></a><p class="title"><b>Table 22. Metastore connection options:</b></p><div class="table-contents"><table summary="Metastore connection options:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--meta-connect &lt;jdbc-uri&gt;</code>
    </td><td style="" align="left">
    Specifies the JDBC connect string used                              to connect to the metastore
    </td></tr></tbody></table></div></div><br class="table-break"><p>By default, a private metastore is instantiated in <code class="literal">$HOME/.sqoop</code>. If
you have configured a hosted metastore with the <code class="literal">sqoop-metastore</code>
tool, you can connect to it by specifying the <code class="literal">--meta-connect</code>
argument. This is a JDBC connect string just like the ones used to
connect to databases for import.</p><p>In <code class="literal">conf/sqoop-site.xml</code>, you can configure
<code class="literal">sqoop.metastore.client.autoconnect.url</code> with this address, so you do not have
to supply <code class="literal">--meta-connect</code> to use a remote metastore. This parameter can
also be modified to move the private metastore to a location on your
filesystem other than your home directory.</p><p>If you configure <code class="literal">sqoop.metastore.client.enable.autoconnect</code> with the
value <code class="literal">false</code>, then you must explicitly supply <code class="literal">--meta-connect</code>.</p><div class="table"><a name="id389611"></a><p class="title"><b>Table 23. Common options:</b></p><div class="table-contents"><table summary="Common options:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="" align="left">
    Print more information while working
    </td></tr></tbody></table></div></div><br class="table-break"></div><div class="section" title="11.3. Saved jobs and passwords"><div class="titlepage"><div><div><h3 class="title"><a name="_saved_jobs_and_passwords"></a>11.3. Saved jobs and passwords</h3></div></div></div><p>The Sqoop metastore is not a secure resource. Multiple users can access
its contents. For this reason, Sqoop does not store passwords in the
metastore. If you create a job that requires a password, you will be
prompted for that password each time you execute the job.</p><p>You can enable passwords in the metastore by setting
<code class="literal">sqoop.metastore.client.record.password</code> to <code class="literal">true</code> in the configuration.</p><p>Note that you have to set <code class="literal">sqoop.metastore.client.record.password</code> to <code class="literal">true</code>
if you are executing saved jobs via Oozie because Sqoop cannot prompt the user
to enter passwords while being executed as Oozie tasks.</p></div><div class="section" title="11.4. Saved jobs and incremental imports"><div class="titlepage"><div><div><h3 class="title"><a name="_saved_jobs_and_incremental_imports"></a>11.4. Saved jobs and incremental imports</h3></div></div></div><p>Incremental imports are performed by comparing the values in a <span class="emphasis"><em>check column</em></span>
against a reference value for the most recent import. For example, if the
<code class="literal">--incremental append</code> argument was specified, along with <code class="literal">--check-column
id</code> and <code class="literal">--last-value 100</code>, all rows with <code class="literal">id &gt; 100</code> will be imported.
If an incremental import is run from the command line, the value which
should be specified as <code class="literal">--last-value</code> in a subsequent incremental import
will be printed to the screen for your reference. If an incremental import is
run from a saved job, this value will be retained in the saved job. Subsequent
runs of <code class="literal">sqoop job --exec someIncrementalJob</code> will continue to import only
newer rows than those previously imported.</p></div></div><div class="section" title="12. sqoop-metastore"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_metastore_literal"></a>12. <code class="literal">sqoop-metastore</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_5">12.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_5">12.2. Syntax</a></span></dt></dl></div><div class="section" title="12.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_5"></a>12.1. Purpose</h3></div></div></div><p>The <code class="literal">metastore</code> tool configures Sqoop to host a shared metadata repository.
Multiple users and/or remote users can define and execute saved jobs (created
with <code class="literal">sqoop job</code>) defined in this metastore.</p><p>Clients must be configured to connect to the metastore in <code class="literal">sqoop-site.xml</code> or
with the <code class="literal">--meta-connect</code> argument.</p></div><div class="section" title="12.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_5"></a>12.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop metastore (generic-args) (metastore-args)
$ sqoop-metastore (generic-args) (metastore-args)</pre><p>Although the Hadoop generic arguments must preceed any metastore arguments,
the metastore arguments can be entered in any order with respect to one
another.</p><div class="table"><a name="id389859"></a><p class="title"><b>Table 24. Metastore management options:</b></p><div class="table-contents"><table summary="Metastore management options:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--shutdown</code>
    </td><td style="" align="left">
    Shuts down a running metastore instance                             on the same machine.
    </td></tr></tbody></table></div></div><br class="table-break"><p>Running <code class="literal">sqoop-metastore</code> launches a shared HSQLDB database instance on
the current machine. Clients can connect to this metastore and create jobs
which can be shared between users for execution.</p><p>The location of the metastore&#8217;s files on disk is controlled by the
<code class="literal">sqoop.metastore.server.location</code> property in <code class="literal">conf/sqoop-site.xml</code>.
This should point to a directory on the local filesystem.</p><p>The metastore is available over TCP/IP. The port is controlled by the
<code class="literal">sqoop.metastore.server.port</code> configuration parameter, and defaults to 16000.</p><p>Clients should connect to the metastore by specifying
<code class="literal">sqoop.metastore.client.autoconnect.url</code> or <code class="literal">--meta-connect</code> with the
value <code class="literal">jdbc:hsqldb:hsql://&lt;server-name&gt;:&lt;port&gt;/sqoop</code>. For example,
<code class="literal">jdbc:hsqldb:hsql://metaserver.example.com:16000/sqoop</code>.</p><p>This metastore may be hosted on a machine within the Hadoop cluster, or
elsewhere on the network.</p></div></div><div class="section" title="13. sqoop-merge"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_merge_literal"></a>13. <code class="literal">sqoop-merge</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_6">13.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_6">13.2. Syntax</a></span></dt></dl></div><div class="section" title="13.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_6"></a>13.1. Purpose</h3></div></div></div><p>The merge tool allows you to combine two datasets where entries in one
dataset should overwrite entries of an older dataset. For example, an
incremental import run in last-modified mode will generate multiple datasets
in HDFS where successively newer data appears in each dataset. The <code class="literal">merge</code>
tool will "flatten" two datasets into one, taking the newest available
records for each primary key.</p></div><div class="section" title="13.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_6"></a>13.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop merge (generic-args) (merge-args)
$ sqoop-merge (generic-args) (merge-args)</pre><p>Although the Hadoop generic arguments must preceed any merge arguments,
the job arguments can be entered in any order with respect to one
another.</p><div class="table"><a name="id390048"></a><p class="title"><b>Table 25. Merge options:</b></p><div class="table-contents"><table summary="Merge options:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--class-name &lt;class&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify the name of the record-specific                             class to use during the merge job.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--jar-file &lt;file&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify the name of the jar to load the                             record class from.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--merge-key &lt;col&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify the name of a column to use as                             the merge key.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--new-data &lt;path&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify the path of the newer dataset.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--onto &lt;path&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify the path of the older dataset.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--target-dir &lt;path&gt;</code>
    </td><td style="" align="left">
    Specify the target path for the output                             of the merge job.
    </td></tr></tbody></table></div></div><br class="table-break"><p>The <code class="literal">merge</code> tool runs a MapReduce job that takes two directories as
input: a newer dataset, and an older one. These are specified with
<code class="literal">--new-data</code> and <code class="literal">--onto</code> respectively. The output of the MapReduce
job will be placed in the directory in HDFS specified by <code class="literal">--target-dir</code>.</p><p>When merging the datasets, it is assumed that there is a unique primary
key value in each record. The column for the primary key is specified
with <code class="literal">--merge-key</code>. Multiple rows in the same dataset should not
have the same primary key, or else data loss may occur.</p><p>To parse the dataset and extract the key column, the auto-generated
class from a previous import must be used. You should specify the
class name and jar file with <code class="literal">--class-name</code> and <code class="literal">--jar-file</code>. If
this is not availab,e you can recreate the class using the <code class="literal">codegen</code>
tool.</p><p>The merge tool is typically run after an incremental import with the
date-last-modified mode (<code class="literal">sqoop import --incremental lastmodified &#8230;</code>).</p><p>Supposing two incremental imports were performed, where some older data
is in an HDFS directory named <code class="literal">older</code> and newer data is in an HDFS
directory named <code class="literal">newer</code>, these could be merged like so:</p><pre class="screen">$ sqoop merge --new-data newer --onto older --target-dir merged \
    --jar-file datatypes.jar --class-name Foo --merge-key id</pre><p>This would run a MapReduce job where the value in the <code class="literal">id</code> column
of each row is used to join rows; rows in the <code class="literal">newer</code> dataset will
be used in preference to rows in the <code class="literal">older</code> dataset.</p><p>This can be used with both SequenceFile-, Avro- and text-based
incremental imports. The file types of the newer and older datasets
must be the same.</p></div></div><div class="section" title="14. sqoop-codegen"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_codegen_literal"></a>14. <code class="literal">sqoop-codegen</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_7">14.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_7">14.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_4">14.3. Example Invocations</a></span></dt></dl></div><div class="section" title="14.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_7"></a>14.1. Purpose</h3></div></div></div><p>The <code class="literal">codegen</code> tool generates Java classes which encapsulate and
interpret imported records. The Java definition of a record is
instantiated as part of the import process, but can also be performed
separately. For example, if Java source is lost, it can be recreated.
New versions of a class can be created which use different delimiters
between fields, and so on.</p></div><div class="section" title="14.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_7"></a>14.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop codegen (generic-args) (codegen-args)
$ sqoop-codegen (generic-args) (codegen-args)</pre><p>Although the Hadoop generic arguments must preceed any codegen arguments,
the codegen arguments can be entered in any order with respect to one
another.</p><div class="table"><a name="id390372"></a><p class="title"><b>Table 26. Common arguments</b></p><div class="table-contents"><table summary="Common arguments" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connect &lt;jdbc-uri&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify JDBC connect string
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connection-manager &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify connection manager class to                                          use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--driver &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Manually specify JDBC driver class                                          to use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hadoop-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override $HADOOP_HOME
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-P</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Read password from console
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--password &lt;password&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication password
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--username &lt;username&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication username
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print more information while working
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--connection-param-file &lt;filename&gt;</code>
    </td><td style="" align="left">
    Optional properties file that                                          provides connection parameters
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id390579"></a><p class="title"><b>Table 27. Code generation arguments:</b></p><div class="table-contents"><table summary="Code generation arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--bindir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Output directory for compiled objects
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--class-name &lt;name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the generated class name. This overrides                         <code class="literal">--package-name</code>. When combined with                          <code class="literal">--jar-file</code>, sets the input class.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--jar-file &lt;file&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Disable code generation; use specified jar
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--outdir &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Output directory for generated code
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--package-name &lt;name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Put auto-generated classes in this package
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--map-column-java &lt;m&gt;</code>
    </td><td style="" align="left">
    Override default mapping from SQL type to                         Java type for configured columns.
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id390734"></a><p class="title"><b>Table 28. Output line formatting arguments:</b></p><div class="table-contents"><table summary="Output line formatting arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field enclosing                                    character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the escape character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the field separator character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the end-of-line character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--mysql-delimiters</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Uses MySQL&#8217;s default delimiter set:                                   fields: <code class="literal">,</code>  lines: <code class="literal">\n</code>                                    escaped-by: <code class="literal">\</code>                                    optionally-enclosed-by: <code class="literal">'</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing character
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id390898"></a><p class="title"><b>Table 29. Input parsing arguments:</b></p><div class="table-contents"><table summary="Input parsing arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field encloser
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input escape                                          character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input field separator
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--input-lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the input end-of-line                                          character
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--input-optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing                                          character
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id391028"></a><p class="title"><b>Table 30. Hive arguments:</b></p><div class="table-contents"><table summary="Hive arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override <code class="literal">$HIVE_HOME</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-import</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Import tables into Hive (Uses Hive&#8217;s                               default delimiters if none are set.)
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-overwrite</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Overwrite existing data in the Hive table.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--create-hive-table</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    If set, then the job will fail if the target hive
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    table exits. By default this property is false.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-table &lt;table-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the table name to use when importing                              to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-drop-import-delims</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Drops <span class="emphasis"><em>\n</em></span>, <span class="emphasis"><em>\r</em></span>, and <span class="emphasis"><em>\01</em></span> from string                              fields when importing to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-delims-replacement</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Replace <span class="emphasis"><em>\n</em></span>, <span class="emphasis"><em>\r</em></span>, and <span class="emphasis"><em>\01</em></span> from string                              fields with user defined string when importing to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-partition-key</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Name of a hive field to partition are                               sharded on
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-partition-value &lt;v&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    String-value that serves as partition key                              for this imported into hive in this job.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--map-column-hive &lt;map&gt;</code>
    </td><td style="" align="left">
    Override default mapping from SQL type to                              Hive type for configured columns.
    </td></tr></tbody></table></div></div><br class="table-break"><p>If Hive arguments are provided to the code generation tool, Sqoop
generates a file containing the HQL statements to create a table and
load data.</p></div><div class="section" title="14.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_4"></a>14.3. Example Invocations</h3></div></div></div><p>Recreate the record interpretation code for the <code class="literal">employees</code> table of a
corporate database:</p><pre class="screen">$ sqoop codegen --connect jdbc:mysql://db.example.com/corp \
    --table employees</pre></div></div><div class="section" title="15. sqoop-create-hive-table"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_create_hive_table_literal"></a>15. <code class="literal">sqoop-create-hive-table</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_8">15.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_8">15.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_5">15.3. Example Invocations</a></span></dt></dl></div><div class="section" title="15.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_8"></a>15.1. Purpose</h3></div></div></div><p>The <code class="literal">create-hive-table</code> tool populates a Hive metastore with a
definition for a table based on a database table previously imported
to HDFS, or one planned to be imported. This effectively performs the
"<code class="literal">--hive-import</code>" step of <code class="literal">sqoop-import</code> without running the
preceeding import.</p><p>If data was already loaded to HDFS, you can use this tool to finish
the pipeline of importing the data to Hive. You can also create Hive tables
with this tool; data then can be imported and populated into
the target after a preprocessing step run by the user.</p></div><div class="section" title="15.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_8"></a>15.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop create-hive-table (generic-args) (create-hive-table-args)
$ sqoop-create-hive-table (generic-args) (create-hive-table-args)</pre><p>Although the Hadoop generic arguments must preceed any create-hive-table
arguments, the create-hive-table arguments can be entered in any order
with respect to one another.</p><div class="table"><a name="id391373"></a><p class="title"><b>Table 31. Common arguments</b></p><div class="table-contents"><table summary="Common arguments" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connect &lt;jdbc-uri&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify JDBC connect string
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connection-manager &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify connection manager class to                                          use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--driver &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Manually specify JDBC driver class                                          to use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hadoop-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override $HADOOP_HOME
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-P</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Read password from console
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--password &lt;password&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication password
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--username &lt;username&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication username
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print more information while working
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--connection-param-file &lt;filename&gt;</code>
    </td><td style="" align="left">
    Optional properties file that                                          provides connection parameters
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id391580"></a><p class="title"><b>Table 32. Hive arguments:</b></p><div class="table-contents"><table summary="Hive arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override <code class="literal">$HIVE_HOME</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-overwrite</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Overwrite existing data in the Hive table.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--create-hive-table</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    If set, then the job will fail if the target hive
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    table exits. By default this property is false.
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hive-table &lt;table-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the table name to use when importing                               to Hive.
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--table</code>
    </td><td style="" align="left">
    The database table to read the                               definition from.
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id391723"></a><p class="title"><b>Table 33. Output line formatting arguments:</b></p><div class="table-contents"><table summary="Output line formatting arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--enclosed-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets a required field enclosing                                    character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--escaped-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the escape character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--fields-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the field separator character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--lines-terminated-by &lt;char&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Sets the end-of-line character
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--mysql-delimiters</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Uses MySQL&#8217;s default delimiter set:                                   fields: <code class="literal">,</code>  lines: <code class="literal">\n</code>                                    escaped-by: <code class="literal">\</code>                                    optionally-enclosed-by: <code class="literal">'</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--optionally-enclosed-by &lt;char&gt;</code>
    </td><td style="" align="left">
    Sets a field enclosing character
    </td></tr></tbody></table></div></div><br class="table-break"><p>Do not use enclosed-by or escaped-by delimiters with output formatting
arguments used to import to Hive. Hive cannot currently parse them.</p></div><div class="section" title="15.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_5"></a>15.3. Example Invocations</h3></div></div></div><p>Define in Hive a table named <code class="literal">emps</code> with a definition based on a
database table named <code class="literal">employees</code>:</p><pre class="screen">$ sqoop create-hive-table --connect jdbc:mysql://db.example.com/corp \
    --table employees --hive-table emps</pre></div></div><div class="section" title="16. sqoop-eval"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_eval_literal"></a>16. <code class="literal">sqoop-eval</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_9">16.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_9">16.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_6">16.3. Example Invocations</a></span></dt></dl></div><div class="section" title="16.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_9"></a>16.1. Purpose</h3></div></div></div><p>The <code class="literal">eval</code> tool allows users to quickly run simple SQL queries against
a database; results are printed to the console. This allows users to
preview their import queries to ensure they import the data they
expect.</p></div><div class="section" title="16.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_9"></a>16.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop eval (generic-args) (eval-args)
$ sqoop-eval (generic-args) (eval-args)</pre><p>Although the Hadoop generic arguments must preceed any eval arguments,
the eval arguments can be entered in any order with respect to one
another.</p><div class="table"><a name="id391975"></a><p class="title"><b>Table 34. Common arguments</b></p><div class="table-contents"><table summary="Common arguments" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connect &lt;jdbc-uri&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify JDBC connect string
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connection-manager &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify connection manager class to                                          use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--driver &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Manually specify JDBC driver class                                          to use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hadoop-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override $HADOOP_HOME
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-P</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Read password from console
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--password &lt;password&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication password
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--username &lt;username&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication username
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print more information while working
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--connection-param-file &lt;filename&gt;</code>
    </td><td style="" align="left">
    Optional properties file that                                          provides connection parameters
    </td></tr></tbody></table></div></div><br class="table-break"><div class="table"><a name="id392181"></a><p class="title"><b>Table 35. SQL evaluation arguments:</b></p><div class="table-contents"><table summary="SQL evaluation arguments:" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">-e,--query &lt;statement&gt;</code>
    </td><td style="" align="left">
    Execute <span class="emphasis"><em><code class="literal">statement</code></em></span> in SQL.
    </td></tr></tbody></table></div></div><br class="table-break"></div><div class="section" title="16.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_6"></a>16.3. Example Invocations</h3></div></div></div><p>Select ten records from the <code class="literal">employees</code> table:</p><pre class="screen">$ sqoop eval --connect jdbc:mysql://db.example.com/corp \
    --query "SELECT * FROM employees LIMIT 10"</pre><p>Insert a row into the <code class="literal">foo</code> table:</p><pre class="screen">$ sqoop eval --connect jdbc:mysql://db.example.com/corp \
    -e "INSERT INTO foo VALUES(42, 'bar')"</pre></div></div><div class="section" title="17. sqoop-list-databases"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_list_databases_literal"></a>17. <code class="literal">sqoop-list-databases</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_10">17.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_10">17.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_7">17.3. Example Invocations</a></span></dt></dl></div><div class="section" title="17.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_10"></a>17.1. Purpose</h3></div></div></div><p>List database schemas present on a server.</p></div><div class="section" title="17.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_10"></a>17.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop list-databases (generic-args) (list-databases-args)
$ sqoop-list-databases (generic-args) (list-databases-args)</pre><p>Although the Hadoop generic arguments must preceed any list-databases
arguments, the list-databases arguments can be entered in any order
with respect to one another.</p><div class="table"><a name="id392334"></a><p class="title"><b>Table 36. Common arguments</b></p><div class="table-contents"><table summary="Common arguments" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connect &lt;jdbc-uri&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify JDBC connect string
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connection-manager &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify connection manager class to                                          use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--driver &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Manually specify JDBC driver class                                          to use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hadoop-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override $HADOOP_HOME
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-P</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Read password from console
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--password &lt;password&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication password
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--username &lt;username&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication username
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print more information while working
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--connection-param-file &lt;filename&gt;</code>
    </td><td style="" align="left">
    Optional properties file that                                          provides connection parameters
    </td></tr></tbody></table></div></div><br class="table-break"></div><div class="section" title="17.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_7"></a>17.3. Example Invocations</h3></div></div></div><p>List database schemas available on a MySQL server:</p><pre class="screen">$ sqoop list-databases --connect jdbc:mysql://database.example.com/
information_schema
employees</pre><div class="note" title="Note" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/note.png"></td><th align="left">Note</th></tr><tr><td align="left" valign="top"><p>This only works with HSQLDB, MySQL and Oracle. When using with Oracle,
it is necessary that the user connecting to the database has DBA privileges.</p></td></tr></table></div></div></div><div class="section" title="18. sqoop-list-tables"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_list_tables_literal"></a>18. <code class="literal">sqoop-list-tables</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_11">18.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_11">18.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_8">18.3. Example Invocations</a></span></dt></dl></div><div class="section" title="18.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_11"></a>18.1. Purpose</h3></div></div></div><p>List tables present in a database.</p></div><div class="section" title="18.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_11"></a>18.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop list-tables (generic-args) (list-tables-args)
$ sqoop-list-tables (generic-args) (list-tables-args)</pre><p>Although the Hadoop generic arguments must preceed any list-tables
arguments, the list-tables arguments can be entered in any order
with respect to one another.</p><div class="table"><a name="id392610"></a><p class="title"><b>Table 37. Common arguments</b></p><div class="table-contents"><table summary="Common arguments" style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Argument
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    Description
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connect &lt;jdbc-uri&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify JDBC connect string
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--connection-manager &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Specify connection manager class to                                          use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--driver &lt;class-name&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Manually specify JDBC driver class                                          to use
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--hadoop-home &lt;dir&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Override $HADOOP_HOME
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--help</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print usage instructions
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">-P</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Read password from console
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--password &lt;password&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication password
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--username &lt;username&gt;</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Set authentication username
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--verbose</code>
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    Print more information while working
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    <code class="literal">--connection-param-file &lt;filename&gt;</code>
    </td><td style="" align="left">
    Optional properties file that                                          provides connection parameters
    </td></tr></tbody></table></div></div><br class="table-break"></div><div class="section" title="18.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_8"></a>18.3. Example Invocations</h3></div></div></div><p>List tables available in the "corp" database:</p><pre class="screen">$ sqoop list-tables --connect jdbc:mysql://database.example.com/corp
employees
payroll_checks
job_descriptions
office_supplies</pre></div></div><div class="section" title="19. sqoop-help"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_help_literal"></a>19. <code class="literal">sqoop-help</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_12">19.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_12">19.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_9">19.3. Example Invocations</a></span></dt></dl></div><div class="section" title="19.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_12"></a>19.1. Purpose</h3></div></div></div><p>List tools available in Sqoop and explain their usage.</p></div><div class="section" title="19.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_12"></a>19.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop help [tool-name]
$ sqoop-help [tool-name]</pre><p>If no tool name is provided (for example, the user runs <code class="literal">sqoop help</code>), then
the available tools are listed. With a tool name, the usage
instructions for that specific tool are presented on the console.</p></div><div class="section" title="19.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_9"></a>19.3. Example Invocations</h3></div></div></div><p>List available tools:</p><pre class="screen">$ sqoop help
usage: sqoop COMMAND [ARGS]

Available commands:
  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  eval               Evaluate a SQL statement and display the results
  export             Export an HDFS directory to a database table

...

See 'sqoop help COMMAND' for information on a specific command.</pre><p>Display usage instructions for the <code class="literal">import</code> tool:</p><pre class="screen">$ bin/sqoop help import
usage: sqoop import [GENERIC-ARGS] [TOOL-ARGS]

Common arguments:
   --connect &lt;jdbc-uri&gt;     Specify JDBC connect string
   --connection-manager &lt;class-name&gt;     Specify connection manager class to use
   --driver &lt;class-name&gt;    Manually specify JDBC driver class to use
   --hadoop-home &lt;dir&gt;      Override $HADOOP_HOME
   --help                   Print usage instructions
-P                          Read password from console
   --password &lt;password&gt;    Set authentication password
   --username &lt;username&gt;    Set authentication username
   --verbose                Print more information while working

Import control arguments:
   --as-avrodatafile             Imports data to Avro Data Files
   --as-sequencefile             Imports data to SequenceFiles
   --as-textfile                 Imports data as plain text (default)
...</pre></div></div><div class="section" title="20. sqoop-version"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_literal_sqoop_version_literal"></a>20. <code class="literal">sqoop-version</code></h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_purpose_13">20.1. Purpose</a></span></dt><dt><span class="section"><a href="#_syntax_13">20.2. Syntax</a></span></dt><dt><span class="section"><a href="#_example_invocations_10">20.3. Example Invocations</a></span></dt></dl></div><div class="section" title="20.1. Purpose"><div class="titlepage"><div><div><h3 class="title"><a name="_purpose_13"></a>20.1. Purpose</h3></div></div></div><p>Display version information for Sqoop.</p></div><div class="section" title="20.2. Syntax"><div class="titlepage"><div><div><h3 class="title"><a name="_syntax_13"></a>20.2. Syntax</h3></div></div></div><pre class="screen">$ sqoop version
$ sqoop-version</pre></div><div class="section" title="20.3. Example Invocations"><div class="titlepage"><div><div><h3 class="title"><a name="_example_invocations_10"></a>20.3. Example Invocations</h3></div></div></div><p>Display the version:</p><pre class="screen">$ sqoop version
Sqoop {revnumber}
git commit id 46b3e06b79a8411320d77c984c3030db47dd1c22
Compiled by aaron@jargon on Mon May 17 13:43:22 PDT 2010</pre></div></div><div class="section" title="21. Compatibility Notes"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_compatibility_notes"></a>21. Compatibility Notes</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_supported_databases">21.1. Supported Databases</a></span></dt><dt><span class="section"><a href="#_mysql">21.2. MySQL</a></span></dt><dd><dl><dt><span class="section"><a href="#_zerodatetimebehavior">21.2.1. zeroDateTimeBehavior</a></span></dt><dt><span class="section"><a href="#_literal_unsigned_literal_columns">21.2.2. <code class="literal">UNSIGNED</code> columns</a></span></dt><dt><span class="section"><a href="#_literal_blob_literal_and_literal_clob_literal_columns">21.2.3. <code class="literal">BLOB</code> and <code class="literal">CLOB</code> columns</a></span></dt><dt><span class="section"><a href="#_importing_views_in_direct_mode">21.2.4. Importing views in direct mode</a></span></dt><dt><span class="section"><a href="#_direct_mode_transactions">21.2.5. Direct-mode Transactions</a></span></dt></dl></dd><dt><span class="section"><a href="#_postgresql">21.3. PostgreSQL</a></span></dt><dd><dl><dt><span class="section"><a href="#_importing_views_in_direct_mode_2">21.3.1. Importing views in direct mode</a></span></dt></dl></dd><dt><span class="section"><a href="#_oracle">21.4. Oracle</a></span></dt><dd><dl><dt><span class="section"><a href="#_dates_and_times">21.4.1. Dates and Times</a></span></dt></dl></dd><dt><span class="section"><a href="#_schema_definition_in_hive">21.5. Schema Definition in Hive</a></span></dt></dl></div><p>Sqoop uses JDBC to connect to databases and adheres to
published standards as much as possible. For databases which do not
support standards-compliant SQL, Sqoop uses alternate codepaths to
provide functionality. In general, Sqoop is believed to be compatible
with a large number of databases, but it is tested with only a few.</p><p>Nonetheless, several database-specific decisions were made in the
implementation of Sqoop, and some databases offer additional settings
which are extensions to the standard.</p><p>This section describes the databases tested with Sqoop, any
exceptions in Sqoop&#8217;s handling of each database relative to the
norm, and any database-specific settings available in Sqoop.</p><div class="section" title="21.1. Supported Databases"><div class="titlepage"><div><div><h3 class="title"><a name="_supported_databases"></a>21.1. Supported Databases</h3></div></div></div><p>While JDBC is a compatibility layer that allows a program to access
many different databases through a common API, slight differences in
the SQL language spoken by each database may mean that Sqoop can&#8217;t use
every database out of the box, or that some databases may be used in
an inefficient manner.</p><p>When you provide a connect string to Sqoop, it inspects the protocol scheme to
determine appropriate vendor-specific logic to use. If Sqoop knows about
a given database, it will work automatically. If not, you may need to
specify the driver class to load via <code class="literal">--driver</code>. This will use a generic
code path which will use standard SQL to access the database. Sqoop provides
some databases with faster, non-JDBC-based access mechanisms. These can be
enabled by specfying the <code class="literal">--direct</code> parameter.</p><p>Sqoop includes vendor-specific support for the following databases:</p><div class="informaltable"><table style="border-collapse: collapse;border-top: 0.5pt solid ; border-bottom: 0.5pt solid ; "><colgroup><col align="left"><col align="left"><col align="left"><col align="left"></colgroup><thead><tr><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Database
    </th><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    version
    </th><th style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">--direct</code> support?
    </th><th style="border-bottom: 0.5pt solid ; " align="left">
    connect string matches
    </th></tr></thead><tbody><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    HSQLDB
    </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    1.8.0+
    </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    No
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">jdbc:hsqldb:*//</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    MySQL
    </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    5.0+
    </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Yes
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">jdbc:mysql://</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    Oracle
    </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    10.2.0+
    </td><td style="border-right: 0.5pt solid ; border-bottom: 0.5pt solid ; " align="left">
    No
    </td><td style="border-bottom: 0.5pt solid ; " align="left">
    <code class="literal">jdbc:oracle:*//</code>
    </td></tr><tr><td style="border-right: 0.5pt solid ; " align="left">
    PostgreSQL
    </td><td style="border-right: 0.5pt solid ; " align="left">
    8.3+
    </td><td style="border-right: 0.5pt solid ; " align="left">
    Yes (import only)
    </td><td style="" align="left">
    <code class="literal">jdbc:postgresql://</code>
    </td></tr></tbody></table></div><p>Sqoop may work with older versions of the databases listed, but we have
only tested it with the versions specified above.</p><p>Even if Sqoop supports a database internally, you may still need to
install the database vendor&#8217;s JDBC driver in your <code class="literal">$SQOOP_HOME/lib</code>
path on your client. Sqoop can load classes from any jars in
<code class="literal">$SQOOP_HOME/lib</code> on the client and will use them as part of any
MapReduce jobs it runs; unlike older versions, you no longer need to
install JDBC jars in the Hadoop library path on your servers.</p></div><div class="section" title="21.2. MySQL"><div class="titlepage"><div><div><h3 class="title"><a name="_mysql"></a>21.2. MySQL</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_zerodatetimebehavior">21.2.1. zeroDateTimeBehavior</a></span></dt><dt><span class="section"><a href="#_literal_unsigned_literal_columns">21.2.2. <code class="literal">UNSIGNED</code> columns</a></span></dt><dt><span class="section"><a href="#_literal_blob_literal_and_literal_clob_literal_columns">21.2.3. <code class="literal">BLOB</code> and <code class="literal">CLOB</code> columns</a></span></dt><dt><span class="section"><a href="#_importing_views_in_direct_mode">21.2.4. Importing views in direct mode</a></span></dt><dt><span class="section"><a href="#_direct_mode_transactions">21.2.5. Direct-mode Transactions</a></span></dt></dl></div><p>JDBC Driver: <a class="ulink" href="http://www.mysql.com/downloads/connector/j/" target="_top">MySQL
Connector/J</a></p><p>MySQL v5.0 and above offers very thorough coverage by Sqoop. Sqoop
has been tested with <code class="literal">mysql-connector-java-5.1.13-bin.jar</code>.</p><div class="section" title="21.2.1. zeroDateTimeBehavior"><div class="titlepage"><div><div><h4 class="title"><a name="_zerodatetimebehavior"></a>21.2.1. zeroDateTimeBehavior</h4></div></div></div><p>MySQL allows values of <code class="literal">'0000-00-00\'</code> for <code class="literal">DATE</code> columns, which is a
non-standard extension to SQL. When communicated via JDBC, these
values are handled in one of three different ways:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Convert to <code class="literal">NULL</code>.
</li><li class="listitem">
Throw an exception in the client.
</li><li class="listitem">
Round to the nearest legal date (<code class="literal">'0001-01-01\'</code>).
</li></ul></div><p>You specify the behavior by using the <code class="literal">zeroDateTimeBehavior</code>
property of the connect string. If a <code class="literal">zeroDateTimeBehavior</code> property
is not specified, Sqoop uses the <code class="literal">convertToNull</code> behavior.</p><p>You can override this behavior. For example:</p><pre class="screen">$ sqoop import --table foo \
    --connect jdbc:mysql://db.example.com/someDb?zeroDateTimeBehavior=round</pre></div><div class="section" title="21.2.2. UNSIGNED columns"><div class="titlepage"><div><div><h4 class="title"><a name="_literal_unsigned_literal_columns"></a>21.2.2. <code class="literal">UNSIGNED</code> columns</h4></div></div></div><p>Columns with type <code class="literal">UNSIGNED</code> in MySQL can hold values between 0 and
2^32 (<code class="literal">4294967295</code>), but the database will report the data type to Sqoop
as <code class="literal">INTEGER</code>, which will can hold values between <code class="literal">-2147483648</code> and
<code class="literal">\+2147483647</code>. Sqoop cannot currently import <code class="literal">UNSIGNED</code> values above
<code class="literal">2147483647</code>.</p></div><div class="section" title="21.2.3. BLOB and CLOB columns"><div class="titlepage"><div><div><h4 class="title"><a name="_literal_blob_literal_and_literal_clob_literal_columns"></a>21.2.3. <code class="literal">BLOB</code> and <code class="literal">CLOB</code> columns</h4></div></div></div><p>Sqoop&#8217;s direct mode does not support imports of <code class="literal">BLOB</code>, <code class="literal">CLOB</code>, or
<code class="literal">LONGVARBINARY</code> columns. Use JDBC-based imports for these
columns; do not supply the <code class="literal">--direct</code> argument to the import tool.</p></div><div class="section" title="21.2.4. Importing views in direct mode"><div class="titlepage"><div><div><h4 class="title"><a name="_importing_views_in_direct_mode"></a>21.2.4. Importing views in direct mode</h4></div></div></div><p>Sqoop is currently not supporting import from view in direct mode. Use
JDBC based (non direct) mode in case that you need to import view (simply
omit <code class="literal">--direct</code> parameter).</p></div><div class="section" title="21.2.5. Direct-mode Transactions"><div class="titlepage"><div><div><h4 class="title"><a name="_direct_mode_transactions"></a>21.2.5. Direct-mode Transactions</h4></div></div></div><p>For performance, each writer will commit the current transaction
approximately every 32 MB of exported data. You can control this
by specifying the following argument <span class="emphasis"><em>before</em></span> any tool-specific arguments: <code class="literal">-D
sqoop.mysql.export.checkpoint.bytes=size</code>, where <span class="emphasis"><em>size</em></span> is a value in
bytes. Set <span class="emphasis"><em>size</em></span> to 0 to disable intermediate checkpoints,
but individual files being exported will continue to be committed
independently of one another.</p><div class="important" title="Important" style="margin-left: 0.5in; margin-right: 0.5in;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/important.png"></td><th align="left">Important</th></tr><tr><td align="left" valign="top"><p>Note that any arguments to Sqoop that are of the form <code class="literal">-D
parameter=value</code> are Hadoop <span class="emphasis"><em>generic arguments</em></span> and must appear before
any tool-specific arguments (for example, <code class="literal">--connect</code>, <code class="literal">--table</code>, etc).</p></td></tr></table></div></div></div><div class="section" title="21.3. PostgreSQL"><div class="titlepage"><div><div><h3 class="title"><a name="_postgresql"></a>21.3. PostgreSQL</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_importing_views_in_direct_mode_2">21.3.1. Importing views in direct mode</a></span></dt></dl></div><p>Sqoop supports JDBC-based connector for PostgreSQL: <a class="ulink" href="http://jdbc.postgresql.org/" target="_top">http://jdbc.postgresql.org/</a></p><p>The connector has been tested using JDBC driver version "9.1-903 JDBC 4" with
PostgreSQL server 9.1.</p><div class="section" title="21.3.1. Importing views in direct mode"><div class="titlepage"><div><div><h4 class="title"><a name="_importing_views_in_direct_mode_2"></a>21.3.1. Importing views in direct mode</h4></div></div></div><p>Sqoop is currently not supporting import from view in direct mode. Use
JDBC based (non direct) mode in case that you need to import view (simply
omit <code class="literal">--direct</code> parameter).</p></div></div><div class="section" title="21.4. Oracle"><div class="titlepage"><div><div><h3 class="title"><a name="_oracle"></a>21.4. Oracle</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_dates_and_times">21.4.1. Dates and Times</a></span></dt></dl></div><p>JDBC Driver:
<a class="ulink" href="http://www.oracle.com/technology/software/tech/java/sqlj_jdbc/htdocs/jdbc_112010.html" target="_top">Oracle
JDBC Thin Driver</a> - Sqoop is compatible with <code class="literal">ojdbc6.jar</code>.</p><p>Sqoop has been tested with Oracle 10.2.0 Express Edition. Oracle is
notable in its different approach to SQL from the ANSI standard, and
its non-standard JDBC driver. Therefore, several features work
differently.</p><div class="section" title="21.4.1. Dates and Times"><div class="titlepage"><div><div><h4 class="title"><a name="_dates_and_times"></a>21.4.1. Dates and Times</h4></div></div></div><p>Oracle JDBC represents <code class="literal">DATE</code> and <code class="literal">TIME</code> SQL types as <code class="literal">TIMESTAMP</code>
values. Any <code class="literal">DATE</code> columns in an Oracle database will be imported as a
<code class="literal">TIMESTAMP</code> in Sqoop, and Sqoop-generated code will store these values
in <code class="literal">java.sql.Timestamp</code> fields.</p><p>When exporting data back to a database, Sqoop parses text fields as
<code class="literal">TIMESTAMP</code> types (with the form <code class="literal">yyyy-mm-dd HH:MM:SS.ffffffff</code>) even
if you expect these fields to be formatted with the JDBC date escape
format of <code class="literal">yyyy-mm-dd</code>. Dates exported to Oracle should be formatted
as full timestamps.</p><p>Oracle also includes the additional date/time types <code class="literal">TIMESTAMP WITH
TIMEZONE</code> and <code class="literal">TIMESTAMP WITH LOCAL TIMEZONE</code>. To support these types,
the user&#8217;s session timezone must be specified. By default, Sqoop will
specify the timezone <code class="literal">"GMT"</code> to Oracle. You can override this setting
by specifying a Hadoop property <code class="literal">oracle.sessionTimeZone</code> on the
command-line when running a Sqoop job. For example:</p><pre class="screen">$ sqoop import -D oracle.sessionTimeZone=America/Los_Angeles \
    --connect jdbc:oracle:thin:@//db.example.com/foo --table bar</pre><p>Note that Hadoop parameters (<code class="literal">-D &#8230;</code>) are <span class="emphasis"><em>generic arguments</em></span> and
must appear before the tool-specific arguments (<code class="literal">--connect</code>,
<code class="literal">--table</code>, and so on).</p><p>Legal values for the session timezone string are enumerated at
<a class="ulink" href="http://download-west.oracle.com/docs/cd/B19306_01/server.102/b14225/applocaledata.htm#i637736" target="_top">http://download-west.oracle.com/docs/cd/B19306_01/server.102/b14225/applocaledata.htm#i637736</a>.</p></div></div><div class="section" title="21.5. Schema Definition in Hive"><div class="titlepage"><div><div><h3 class="title"><a name="_schema_definition_in_hive"></a>21.5. Schema Definition in Hive</h3></div></div></div><p>Hive users will note that there is not a one-to-one mapping between
SQL types and Hive types. In general, SQL types that do not have a
direct mapping (for example, <code class="literal">DATE</code>, <code class="literal">TIME</code>, and <code class="literal">TIMESTAMP</code>) will be coerced to
<code class="literal">STRING</code> in Hive. The <code class="literal">NUMERIC</code> and <code class="literal">DECIMAL</code> SQL types will be coerced to
<code class="literal">DOUBLE</code>. In these cases, Sqoop will emit a warning in its log messages
informing you of the loss of precision.</p></div></div><div class="section" title="22. Getting Support"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_getting_support"></a>22. Getting Support</h2></div></div></div><p>Some general information is available at the
<a class="ulink" href="http://sqoop.apache.org/" target="_top">http://sqoop.apache.org/</a></p><p>Report bugs in Sqoop to the issue tracker at
<a class="ulink" href="https://issues.apache.org/jira/browse/SQOOP" target="_top">https://issues.apache.org/jira/browse/SQOOP</a>.</p><p>Questions and discussion regarding the usage of Sqoop should be directed to the
<a class="ulink" href="http://sqoop.apache.org/mail-lists.html" target="_top">sqoop-user mailing list</a>.</p><p>Before contacting either forum, run your Sqoop job with the
<code class="literal">--verbose</code> flag to acquire as much debugging information as
possible. Also report the string returned by <code class="literal">sqoop version</code> as
well as the version of Hadoop you are running (<code class="literal">hadoop version</code>).</p></div><div class="section" title="23. Troubleshooting"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="_troubleshooting"></a>23. Troubleshooting</h2></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_general_troubleshooting_process">23.1. General Troubleshooting Process</a></span></dt><dt><span class="section"><a href="#_specific_troubleshooting_tips">23.2. Specific Troubleshooting Tips</a></span></dt><dd><dl><dt><span class="section"><a href="#_oracle_connection_reset_errors">23.2.1. Oracle: Connection Reset Errors</a></span></dt><dt><span class="section"><a href="#_oracle_case_sensitive_catalog_query_errors">23.2.2. Oracle: Case-Sensitive Catalog Query Errors</a></span></dt><dt><span class="section"><a href="#_mysql_connection_failure">23.2.3. MySQL: Connection Failure</a></span></dt><dt><span class="section"><a href="#_oracle_ora_00933_error_sql_command_not_properly_ended">23.2.4. Oracle: ORA-00933 error (SQL command not properly ended)</a></span></dt><dt><span class="section"><a href="#_mysql_import_of_tinyint_1_from_mysql_behaves_strangely">23.2.5. MySQL: Import of TINYINT(1) from MySQL behaves strangely</a></span></dt></dl></dd></dl></div><div class="section" title="23.1. General Troubleshooting Process"><div class="titlepage"><div><div><h3 class="title"><a name="_general_troubleshooting_process"></a>23.1. General Troubleshooting Process</h3></div></div></div><p>The following steps should be followed to troubleshoot any failure that you
encounter while running Sqoop.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Turn on verbose output by executing the same command again and specifying
  the <code class="literal">--verbose</code> option. This produces more debug output on the console
  which can be inspected to identify any obvious errors.
</li><li class="listitem">
Look at the task logs from Hadoop to see if there are any specific failures
  recorded there. It is possible that the failure that occurs while task
  execution is not relayed correctly to the console.
</li><li class="listitem">
Make sure that the necessary input files or input/output tables are present
  and can be accessed by the user that Sqoop is executing as or connecting to
  the database as. It is possible that the necessary files or tables are present
  but the specific user that Sqoop connects as does not have the necessary
  permissions to access these files.
</li><li class="listitem">
If you are doing a compound action such as populating a Hive table or
  partition, try breaking the job into two separate actions to see where the
  problem really occurs. For example if an import that creates and populates a
  Hive table is failing, you can break it down into two steps - first for doing
  the import alone, and the second to create a Hive table without the import
  using the <code class="literal">create-hive-table</code> tool. While this does not address the original
  use-case of populating the Hive table, it does help narrow down the problem
  to either regular import or during the creation and population of Hive table.
</li><li class="listitem">
Search the mailing lists archives and JIRA for keywords relating to the
  problem. It is possible that you may find a solution discussed there that
  will help you solve or work-around your problem.
</li></ul></div></div><div class="section" title="23.2. Specific Troubleshooting Tips"><div class="titlepage"><div><div><h3 class="title"><a name="_specific_troubleshooting_tips"></a>23.2. Specific Troubleshooting Tips</h3></div></div></div><div class="toc"><dl><dt><span class="section"><a href="#_oracle_connection_reset_errors">23.2.1. Oracle: Connection Reset Errors</a></span></dt><dt><span class="section"><a href="#_oracle_case_sensitive_catalog_query_errors">23.2.2. Oracle: Case-Sensitive Catalog Query Errors</a></span></dt><dt><span class="section"><a href="#_mysql_connection_failure">23.2.3. MySQL: Connection Failure</a></span></dt><dt><span class="section"><a href="#_oracle_ora_00933_error_sql_command_not_properly_ended">23.2.4. Oracle: ORA-00933 error (SQL command not properly ended)</a></span></dt><dt><span class="section"><a href="#_mysql_import_of_tinyint_1_from_mysql_behaves_strangely">23.2.5. MySQL: Import of TINYINT(1) from MySQL behaves strangely</a></span></dt></dl></div><div class="section" title="23.2.1. Oracle: Connection Reset Errors"><div class="titlepage"><div><div><h4 class="title"><a name="_oracle_connection_reset_errors"></a>23.2.1. Oracle: Connection Reset Errors</h4></div></div></div><p>Problem: When using the default Sqoop connector for Oracle, some data does
get transferred, but during the map-reduce job a lot of errors are reported
as below:</p><pre class="screen">11/05/26 16:23:47 INFO mapred.JobClient: Task Id : attempt_201105261333_0002_m_000002_0, Status : FAILED
java.lang.RuntimeException: java.lang.RuntimeException: java.sql.SQLRecoverableException: IO Error: Connection reset
at com.cloudera.sqoop.mapreduce.db.DBInputFormat.setConf(DBInputFormat.java:164)
at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:62)
at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:605)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:322)
at org.apache.hadoop.mapred.Child$4.run(Child.java:268)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1115)
at org.apache.hadoop.mapred.Child.main(Child.java:262)
Caused by: java.lang.RuntimeException: java.sql.SQLRecoverableException: IO Error: Connection reset
at com.cloudera.sqoop.mapreduce.db.DBInputFormat.getConnection(DBInputFormat.java:190)
at com.cloudera.sqoop.mapreduce.db.DBInputFormat.setConf(DBInputFormat.java:159)
... 9 more
Caused by: java.sql.SQLRecoverableException: IO Error: Connection reset
at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:428)
at oracle.jdbc.driver.PhysicalConnection.&lt;init&gt;(PhysicalConnection.java:536)
at oracle.jdbc.driver.T4CConnection.&lt;init&gt;(T4CConnection.java:228)
at oracle.jdbc.driver.T4CDriverExtension.getConnection(T4CDriverExtension.java:32)
at oracle.jdbc.driver.OracleDriver.connect(OracleDriver.java:521)
at java.sql.DriverManager.getConnection(DriverManager.java:582)
at java.sql.DriverManager.getConnection(DriverManager.java:185)
at com.cloudera.sqoop.mapreduce.db.DBConfiguration.getConnection(DBConfiguration.java:152)
at com.cloudera.sqoop.mapreduce.db.DBInputFormat.getConnection(DBInputFormat.java:184)
... 10 more
Caused by: java.net.SocketException: Connection reset
at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:96)
at java.net.SocketOutputStream.write(SocketOutputStream.java:136)
at oracle.net.ns.DataPacket.send(DataPacket.java:199)
at oracle.net.ns.NetOutputStream.flush(NetOutputStream.java:211)
at oracle.net.ns.NetInputStream.getNextPacket(NetInputStream.java:227)
at oracle.net.ns.NetInputStream.read(NetInputStream.java:175)
at oracle.net.ns.NetInputStream.read(NetInputStream.java:100)
at oracle.net.ns.NetInputStream.read(NetInputStream.java:85)
at oracle.jdbc.driver.T4CSocketInputStreamWrapper.readNextPacket(T4CSocketInputStreamWrapper.java:123)
at oracle.jdbc.driver.T4CSocketInputStreamWrapper.read(T4CSocketInputStreamWrapper.java:79)
at oracle.jdbc.driver.T4CMAREngine.unmarshalUB1(T4CMAREngine.java:1122)
at oracle.jdbc.driver.T4CMAREngine.unmarshalSB1(T4CMAREngine.java:1099)
at oracle.jdbc.driver.T4CTTIfun.receive(T4CTTIfun.java:288)
at oracle.jdbc.driver.T4CTTIfun.doRPC(T4CTTIfun.java:191)
at oracle.jdbc.driver.T4CTTIoauthenticate.doOAUTH(T4CTTIoauthenticate.java:366)
at oracle.jdbc.driver.T4CTTIoauthenticate.doOAUTH(T4CTTIoauthenticate.java:752)
at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:366)
... 18 more</pre><p>Solution: This problem occurs primarily due to the lack of a fast random
number generation device on the host where the map tasks execute. On
typical Linux systems this can be addressed by setting the following
property in the <code class="literal">java.security</code> file:</p><pre class="screen">java.security.egd=file:/dev/../dev/urandom</pre><p>The <code class="literal">java.security</code> file can be found under <code class="literal">$JAVA_HOME/jre/lib/security</code>
directory. Alternatively, this property can also be specified on the
command line via:</p><pre class="screen">-D mapred.child.java.opts="\-Djava.security.egd=file:/dev/../dev/urandom"+</pre></div><div class="section" title="23.2.2. Oracle: Case-Sensitive Catalog Query Errors"><div class="titlepage"><div><div><h4 class="title"><a name="_oracle_case_sensitive_catalog_query_errors"></a>23.2.2. Oracle: Case-Sensitive Catalog Query Errors</h4></div></div></div><p>Problem: While working with Oracle you may encounter problems when Sqoop can
not figure out column names. This happens because the catalog queries that
Sqoop uses for Oracle expect the correct case to be specified for the
user name and table name.</p><p>One example, using --hive-import and resulting in a NullPointerException:</p><pre class="screen">1/09/21 17:18:49 INFO manager.OracleManager: Time zone has been set to
GMT
11/09/21 17:18:49 DEBUG manager.SqlManager: Using fetchSize for next
query: 1000
11/09/21 17:18:49 INFO manager.SqlManager: Executing SQL statement:
SELECT t.* FROM addlabel_pris t WHERE 1=0
11/09/21 17:18:49 DEBUG manager.OracleManager$ConnCache: Caching
released connection for jdbc:oracle:thin:
11/09/21 17:18:49 ERROR sqoop.Sqoop: Got exception running Sqoop:
java.lang.NullPointerException
java.lang.NullPointerException
at com.cloudera.sqoop.hive.TableDefWriter.getCreateTableStmt(TableDefWriter.java:148)
at com.cloudera.sqoop.hive.HiveImport.importTable(HiveImport.java:187)
at com.cloudera.sqoop.tool.ImportTool.importTable(ImportTool.java:362)
at com.cloudera.sqoop.tool.ImportTool.run(ImportTool.java:423)
at com.cloudera.sqoop.Sqoop.run(Sqoop.java:144)
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
at com.cloudera.sqoop.Sqoop.runSqoop(Sqoop.java:180)
at com.cloudera.sqoop.Sqoop.runTool(Sqoop.java:219)
at com.cloudera.sqoop.Sqoop.runTool(Sqoop.java:228)
at com.cloudera.sqoop.Sqoop.main(Sqoop.java:237)</pre><div class="orderedlist" title="Solution:"><p class="title"><b>Solution:</b></p><ol class="orderedlist" type="1"><li class="listitem">
Specify the user name, which Sqoop is connecting as, in upper case (unless
it was created with mixed/lower case within quotes).
</li><li class="listitem">
Specify the table name, which you are working with, in upper case (unless
it was created with mixed/lower case within quotes).
</li></ol></div></div><div class="section" title="23.2.3. MySQL: Connection Failure"><div class="titlepage"><div><div><h4 class="title"><a name="_mysql_connection_failure"></a>23.2.3. MySQL: Connection Failure</h4></div></div></div><p>Problem: While importing a MySQL table into Sqoop, if you do not have
the necessary permissions to access your MySQL database over the network,
you may get the below connection failure.</p><pre class="screen">Caused by: com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure</pre><p>Solution: First, verify that you can connect to the database from the node where
you are running Sqoop:</p><pre class="screen">$ mysql --host=&lt;IP Address&gt; --database=test --user=&lt;username&gt; --password=&lt;password&gt;</pre><p>If this works, it rules out any problem with the client network configuration
or security/authentication configuration.</p><p>Add the network port for the server to your my.cnf file <code class="literal">/etc/my.cnf</code>:</p><pre class="screen">[mysqld]
port = xxxx</pre><p>Set up a user account to connect via Sqoop.
Grant permissions to the user to access the database over the network:
(1.) Log into MySQL as root <code class="literal">mysql -u root -p&lt;ThisIsMyPassword&gt;</code>.
(2.) Issue the following command:</p><pre class="screen">mysql&gt; grant all privileges on test.* to 'testuser'@'%' identified by 'testpassword'</pre><p>Note that doing this will enable the testuser to connect to the
MySQL server from any IP address. While this will work, it is not
advisable for a production environment. We advise consulting with your
DBA to grant the necessary privileges based on the setup topology.</p><p>If the database server&#8217;s IP address changes, unless it is bound to
a static hostname in your server, the connect string passed into Sqoop
will also need to be changed.</p></div><div class="section" title="23.2.4. Oracle: ORA-00933 error (SQL command not properly ended)"><div class="titlepage"><div><div><h4 class="title"><a name="_oracle_ora_00933_error_sql_command_not_properly_ended"></a>23.2.4. Oracle: ORA-00933 error (SQL command not properly ended)</h4></div></div></div><p>Problem: While working with Oracle you may encounter the below problem
when the Sqoop command explicitly specifies the --driver
&lt;driver name&gt; option. When the driver option is included in
the Sqoop command, the built-in connection manager selection defaults to the
generic connection manager, which causes this issue with Oracle. If the
driver option is not specified, the built-in connection manager selection
mechanism selects the Oracle specific connection manager which generates
valid SQL for Oracle and uses the driver "oracle.jdbc.OracleDriver".</p><pre class="screen">ERROR manager.SqlManager: Error executing statement:
java.sql.SQLSyntaxErrorException: ORA-00933: SQL command not properly ended</pre><p>Solution: Omit the option --driver oracle.jdbc.driver.OracleDriver and then
re-run the Sqoop command.</p></div><div class="section" title="23.2.5. MySQL: Import of TINYINT(1) from MySQL behaves strangely"><div class="titlepage"><div><div><h4 class="title"><a name="_mysql_import_of_tinyint_1_from_mysql_behaves_strangely"></a>23.2.5. MySQL: Import of TINYINT(1) from MySQL behaves strangely</h4></div></div></div><p>Problem: Sqoop is treating TINYINT(1) columns as booleans, which is for example
causing issues with HIVE import. This is because by default the MySQL JDBC connector
maps the TINYINT(1) to java.sql.Types.BIT, which Sqoop by default maps to Boolean.</p><p>Solution: A more clean solution is to force MySQL JDBC Connector to stop
converting TINYINT(1) to java.sql.Types.BIT by adding <code class="literal">tinyInt1isBit=false</code> into your
JDBC path (to create something like <code class="literal">jdbc:mysql://localhost/test?tinyInt1isBit=false</code>).
Another solution would be to explicitly override the column mapping for the datatype
TINYINT(1) column. For example, if the column name is foo, then pass the following
option to Sqoop during import: --map-column-hive foo=tinyint. In the case of non-Hive
imports to HDFS, use --map-column-java foo=integer.</p></div></div></div></div><div class="footer-text"><span align="center"><a href="index.html"><img src="images/home.png" alt="Documentation Home"></a></span><br>
  This document was built from Sqoop source available at
  <a href="http://svn.apache.org/repos/asf/sqoop/trunk/">http://svn.apache.org/repos/asf/sqoop/trunk/</a>.
  </div></body></html>
